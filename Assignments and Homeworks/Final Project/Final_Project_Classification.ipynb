{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k68Yc5IIrmk1"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3WAfSNSPbpx"
      },
      "source": [
        "## adding necessary tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZCWZ6c5rXNv",
        "outputId": "fb8ee9be-76d8-45a9-f9b2-ecd1f76d62c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-1.1.1-cp310-cp310-manylinux1_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.1\n"
          ]
        }
      ],
      "source": [
        "#installing deep graph library\n",
        "!pip3 install dgl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ddKV0Zsrhuj",
        "outputId": "41bca140-2499-46af-e982-1170cb62c7da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dglgo\n",
            "  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.7.0)\n",
            "Collecting isort>=5.10.1 (from dglgo)\n",
            "  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autopep8>=1.6.0 (from dglgo)\n",
            "  Downloading autopep8-2.0.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpydoc>=1.1.0 (from dglgo)\n",
            "  Downloading numpydoc-1.5.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.10.9)\n",
            "Collecting ruamel.yaml>=0.17.20 (from dglgo)\n",
            "  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0)\n",
            "Collecting ogb>=1.3.3 (from dglgo)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit-pypi (from dglgo)\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n",
            "Collecting pycodestyle>=2.10.0 (from autopep8>=1.6.0->dglgo)\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Collecting sphinx>=4.2 (from numpydoc>=1.1.0->dglgo)\n",
            "  Downloading sphinx-7.0.1-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.65.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.26.16)\n",
            "Collecting outdated>=0.2.0 (from ogb>=1.3.3->dglgo)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.6.3)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.20->dglgo)\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb>=1.3.3->dglgo)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
            "Collecting docutils<0.21,>=0.18.1 (from sphinx>=4.2->numpydoc>=1.1.0->dglgo)\n",
            "  Downloading docutils-0.20.1-py3-none-any.whl (572 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.7/572.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (16.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=2d25704bc335eaff4d5af35bb089884192334360cd9a39c7ebb134ae1ba678d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, pycodestyle, isort, docutils, sphinx, ruamel.yaml, outdated, autopep8, numpydoc, ogb, dglgo\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 3.5.4\n",
            "    Uninstalling Sphinx-3.5.4:\n",
            "      Successfully uninstalled Sphinx-3.5.4\n",
            "Successfully installed autopep8-2.0.2 dglgo-0.0.2 docutils-0.20.1 isort-5.12.0 littleutils-0.2.2 numpydoc-1.5.0 ogb-1.3.6 outdated-0.2.2 pycodestyle-2.10.0 rdkit-pypi-2022.9.5 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7 sphinx-7.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install dglgo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wzZCsAX0rkP5"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os #to create and dealing with directory\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl #deep graph library\n",
        "import numpy as np #numerical functions\n",
        "import networkx as nx #to represent graph and dealing with graph\n",
        "import torch #for neural network\n",
        "import torch.nn as nn\n",
        "import dgl.function as fn #to catch functions\n",
        "import torch.nn.functional as F #neural network functions\n",
        "import shutil #help us import dataset\n",
        "from torch.utils.data import DataLoader #to load data\n",
        "import cloudpickle\n",
        "from dgl.nn import GraphConv\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAAnLNwzPeok"
      },
      "source": [
        "## loading dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXnVv529Qs7j"
      },
      "source": [
        "using HIV dataset<br>\n",
        "HIV dataset was introduced by the Drug Therapeutics Program (DTP) AIDS Antiviral Screen, which tested the ability to inhibit HIV replication for over 40000 compounds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hmf5Zij0PhRa"
      },
      "outputs": [],
      "source": [
        "current_dir = \"./\"\n",
        "checkpoint_path = current_dir + \"save_models/model_checkpoints/\" + \"checkpoint\"\n",
        "os.makedirs(checkpoint_path, exist_ok=True)\n",
        "\n",
        "best_model_path = current_dir + \"save_models/best_model/\"\n",
        "\n",
        "folder_data_temp = current_dir +\"data_temp/\"\n",
        "shutil.rmtree(folder_data_temp, ignore_errors=True)\n",
        "\n",
        "path_save = current_dir + \"graph_classification.zip\"\n",
        "shutil.unpack_archive(path_save, folder_data_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3crmBfJsQ6w6"
      },
      "source": [
        "Defining a custom pytorch classification dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rVzZcUrmPhdf"
      },
      "outputs": [],
      "source": [
        "\"\"\" Classification Dataset \"\"\"\n",
        "class DGLDatasetClass(torch.utils.data.Dataset):\n",
        "    def __init__(self, address):\n",
        "            self.address=address+\".bin\"\n",
        "            self.list_graphs, train_labels_masks_globals = dgl.load_graphs(self.address)\n",
        "            num_graphs =len(self.list_graphs)\n",
        "            self.labels = train_labels_masks_globals[\"labels\"].view(num_graphs,-1)\n",
        "            self.masks = train_labels_masks_globals[\"masks\"].view(num_graphs,-1)\n",
        "            self.globals = train_labels_masks_globals[\"globals\"].view(num_graphs,-1)\n",
        "    def __len__(self):\n",
        "        return len(self.list_graphs)\n",
        "    def __getitem__(self, idx):\n",
        "        return  self.list_graphs[idx], self.labels[idx], self.masks[idx], self.globals[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt1gLdCbTDuv"
      },
      "source": [
        "performing train and test and split according to file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKBZ61-iSiBK",
        "outputId": "cf4376a7-db02-4ef3-afa2-04467cc9e674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32901 4112 4114\n"
          ]
        }
      ],
      "source": [
        "path_data_temp = folder_data_temp + \"scaffold\"+\"_\"+str(0) #str(0) is because we use scaffold_0 from main datasets at source\n",
        "train_set = DGLDatasetClass(address=path_data_temp+\"_train\")\n",
        "val_set = DGLDatasetClass(address=path_data_temp+\"_val\")\n",
        "test_set = DGLDatasetClass(address=path_data_temp+\"_test\")\n",
        "\n",
        "print(len(train_set), len(val_set), len(test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "p4L0-DmXUbn1"
      },
      "outputs": [],
      "source": [
        "def collate(batch):\n",
        "    # batch is a list of tuples (graphs, labels, masks, globals)\n",
        "    # Concatenate a sequence of graphs\n",
        "    graphs = [e[0] for e in batch]\n",
        "    g = dgl.batch(graphs)\n",
        "\n",
        "    # Concatenate a sequence of tensors (labels) along a new dimension\n",
        "    labels = [e[1] for e in batch]\n",
        "    labels = torch.stack(labels, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (masks) along a new dimension\n",
        "    masks = [e[2] for e in batch]\n",
        "    masks = torch.stack(masks, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (globals) along a new dimension\n",
        "    globals = [e[3] for e in batch]\n",
        "    globals = torch.stack(globals, 0)\n",
        "\n",
        "    return g, labels, masks, globals\n",
        "\n",
        "def loader(batch_size = 64):\n",
        "    train_dataloader = DataLoader(train_set,\n",
        "                              batch_size=batch_size,\n",
        "                              collate_fn=collate,\n",
        "                              drop_last=False,\n",
        "                              shuffle=True,\n",
        "                              num_workers=1)\n",
        "\n",
        "    val_dataloader =  DataLoader(val_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "\n",
        "    test_dataloader = DataLoader(test_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H-YeEh_lWvxd"
      },
      "outputs": [],
      "source": [
        "train_dataloader, val_dataloader, test_dataloader = loader(batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE2gXFf5ggr3"
      },
      "source": [
        "# Model Defining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N-lUvrPVhUQG"
      },
      "outputs": [],
      "source": [
        "#HIV has only 1 task\n",
        "num_tasks = 1\n",
        "\n",
        "# Size of global feature of each graph\n",
        "global_size = 200\n",
        "\n",
        "# Number of epochs to train the model\n",
        "num_epochs = 100\n",
        "\n",
        "# Number of steps to wait if the model performance on the validation set does not improve\n",
        "patience = 10\n",
        "\n",
        "#Configurations to instantiate the model\n",
        "config = {\"node_feature_size\":127, \"edge_feature_size\":12, \"hidden_size\":100}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFJQ3FT3pEX8"
      },
      "source": [
        "for this project we'll use 8 models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4HSkQEPpRoj"
      },
      "source": [
        "## model1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VGE7xjtpUAw"
      },
      "source": [
        "using graph convolutional<br>\n",
        "3 layer<br>\n",
        "no drop out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CRIlI66qpPE6"
      },
      "outputs": [],
      "source": [
        "class model1(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv3 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZCQWj_5rzrO"
      },
      "source": [
        "Function to Compute Score of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "p1ST5aN6rfWJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    metric = roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        prediction_all= torch.empty(0)\n",
        "        labels_all= torch.empty(0)\n",
        "        masks_all= torch.empty(0)\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.sigmoid(prediction)\n",
        "            prediction_all = torch.cat((prediction_all, prediction), 0)\n",
        "            labels_all = torch.cat((labels_all, labels), 0)\n",
        "            masks_all = torch.cat((masks_all, masks), 0)\n",
        "        average = torch.tensor([0.])\n",
        "        for i in range(num_tasks):\n",
        "            a1 = prediction_all[:, i][masks_all[:,i]==1]\n",
        "            a2 = labels_all[:, i][masks_all[:,i]==1]\n",
        "            try:\n",
        "                t = metric(a2.int().cpu(), a1.cpu()).item()\n",
        "            except ValueError:\n",
        "                t = 0\n",
        "            average += t\n",
        "    return average.item()/num_tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOXDLkjurxTp"
      },
      "source": [
        "loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pgXJIwczrtr_"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x303YlhDr72Q"
      },
      "source": [
        "training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ClOv1nfSr9IM"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZJ2UVWvCsFZS"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model1(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W_tVxDbsOof"
      },
      "source": [
        "Function to compute test set score of the final saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "N8-bJXRusO8W"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = model1(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkiVFlansbSB"
      },
      "source": [
        "Train the model and evaluate its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgdJPui8sbqF",
        "outputId": "372df609-6695-478d-aafd-70772e629f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.234 | Valid Score: 0.555\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.555 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.162 | Valid Score: 0.595\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.595 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.155 | Valid Score: 0.653\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.653 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.150 | Valid Score: 0.701\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.701 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.148 | Valid Score: 0.727\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.727 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.146 | Valid Score: 0.739\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.739 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.145 | Valid Score: 0.748\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.748 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.145 | Valid Score: 0.753\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.753 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.144 | Valid Score: 0.756\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.756 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.144 | Valid Score: 0.757\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.757 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.143 | Valid Score: 0.759\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.759 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.143 | Valid Score: 0.760\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.143 | Valid Score: 0.761\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.761 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.143 | Valid Score: 0.762\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.762 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.142 | Valid Score: 0.763\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.763 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.142 | Valid Score: 0.764\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.141 | Valid Score: 0.766\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.766 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.141 | Valid Score: 0.766\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.766 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.141 | Valid Score: 0.766\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.766 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 0.141 | Valid Score: 0.769\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 21/100 | Training Loss: 0.140 | Valid Score: 0.768\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.140 | Valid Score: 0.769\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 23/100 | Training Loss: 0.140 | Valid Score: 0.767\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 24/100 | Training Loss: 0.141 | Valid Score: 0.769\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 0.139 | Valid Score: 0.770\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.770 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 26/100 | Training Loss: 0.141 | Valid Score: 0.768\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.770 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.139 | Valid Score: 0.770\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.770 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 0.139 | Valid Score: 0.772\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.772 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 29/100 | Training Loss: 0.138 | Valid Score: 0.770\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.772 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 30/100 | Training Loss: 0.138 | Valid Score: 0.772\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.772 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 31/100 | Training Loss: 0.139 | Valid Score: 0.768\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.772 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 0.137 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.774 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 33/100 | Training Loss: 0.137 | Valid Score: 0.770\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.774 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 34/100 | Training Loss: 0.140 | Valid Score: 0.771\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.774 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 35/100 | Training Loss: 0.138 | Valid Score: 0.772\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.774 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 36/100 | Training Loss: 0.137 | Valid Score: 0.772\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.774 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 37/100 | Training Loss: 0.136 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.774 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 38/100 | Training Loss: 0.136 | Valid Score: 0.772\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.774 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.136 | Valid Score: 0.776\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 40/100 | Training Loss: 0.136 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 41/100 | Training Loss: 0.135 | Valid Score: 0.775\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 42/100 | Training Loss: 0.135 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 0.135 | Valid Score: 0.776\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 44/100 | Training Loss: 0.135 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 0.135 | Valid Score: 0.778\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 46/100 | Training Loss: 0.135 | Valid Score: 0.775\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 47/100 | Training Loss: 0.134 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 48/100 | Training Loss: 0.135 | Valid Score: 0.775\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 49/100 | Training Loss: 0.134 | Valid Score: 0.777\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 50/100 | Training Loss: 0.135 | Valid Score: 0.776\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 51/100 | Training Loss: 0.133 | Valid Score: 0.778\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 52/100 | Training Loss: 0.133 | Valid Score: 0.778\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 0.133 | Valid Score: 0.780\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.780 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 0.133 | Valid Score: 0.780\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.780 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 0.133 | Valid Score: 0.780\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.780 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 56/100 | Training Loss: 0.133 | Valid Score: 0.777\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.780 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 57/100 | Training Loss: 0.132 | Valid Score: 0.780\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.780 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 0.132 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 59/100 | Training Loss: 0.132 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 0.132 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 61/100 | Training Loss: 0.132 | Valid Score: 0.782\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 62/100 | Training Loss: 0.132 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 63/100 | Training Loss: 0.133 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 64/100 | Training Loss: 0.131 | Valid Score: 0.782\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 65/100 | Training Loss: 0.131 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 66/100 | Training Loss: 0.131 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 67/100 | Training Loss: 0.131 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 0.131 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 0.131 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 0.130 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 71/100 | Training Loss: 0.130 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 72/100 | Training Loss: 0.130 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 0.130 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 74/100 | Training Loss: 0.130 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 75/100 | Training Loss: 0.130 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 76/100 | Training Loss: 0.129 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 77/100 | Training Loss: 0.131 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 78/100 | Training Loss: 0.129 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 79/100 | Training Loss: 0.129 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 80/100 | Training Loss: 0.128 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 0.788 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 0.129 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 0.788 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 82/100 | Training Loss: 0.128 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 0.788 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 83/100 | Training Loss: 0.130 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 84/100 | Training Loss: 0.128 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 85/100 | Training Loss: 0.129 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 86/100 | Training Loss: 0.128 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 87/100 | Training Loss: 0.128 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 88/100 | Training Loss: 0.127 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 89/100 | Training Loss: 0.127 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 90/100 | Training Loss: 0.127 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 91/100 | Training Loss: 0.127 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 92/100 | Training Loss: 0.127 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 93/100 | Training Loss: 0.127 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 94/100 | Training Loss: 0.127 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 95/100 | Training Loss: 0.127 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 96/100 | Training Loss: 0.126 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 97/100 | Training Loss: 0.126 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 98/100 | Training Loss: 0.126 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 99/100 | Training Loss: 0.126 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 100/100 | Training Loss: 0.126 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.792 \n",
            "\n",
            "Test Score: 0.738 \n",
            "\n",
            "Execution time: 1146.850 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmijM11nptgE"
      },
      "source": [
        "## model2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNlFSJP4ptgE"
      },
      "source": [
        "using graph sage<br>\n",
        "3 layer<br>\n",
        "no drop out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jCrtySVMuz0z"
      },
      "outputs": [],
      "source": [
        "#defining Graph sage class from scratch\n",
        "class SAGEConv(nn.Module):\n",
        "    \"\"\"Graph convolution module used by the GraphSAGE model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_feat : int\n",
        "        Input feature size.\n",
        "    out_feat : int\n",
        "        Output feature size.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv, self).__init__()\n",
        "        # A linear submodule for projecting the input and neighbor feature to the output.\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        \"\"\"Forward computation\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        g : Graph\n",
        "            The input graph.\n",
        "        h : Tensor\n",
        "            The input node feature.\n",
        "        \"\"\"\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            # update_all is a message passing API.\n",
        "            g.update_all(\n",
        "                message_func=fn.copy_u(\"h\", \"m\"),\n",
        "                reduce_func=fn.mean(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-12ADlyvssFb"
      },
      "outputs": [],
      "source": [
        "class model2(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.conv3 = SAGEConv(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwjFz83HssFk"
      },
      "source": [
        "Function to Compute Score of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nK08kHp2ssFk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    metric = roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        prediction_all= torch.empty(0)\n",
        "        labels_all= torch.empty(0)\n",
        "        masks_all= torch.empty(0)\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.sigmoid(prediction)\n",
        "            prediction_all = torch.cat((prediction_all, prediction), 0)\n",
        "            labels_all = torch.cat((labels_all, labels), 0)\n",
        "            masks_all = torch.cat((masks_all, masks), 0)\n",
        "        average = torch.tensor([0.])\n",
        "        for i in range(num_tasks):\n",
        "            a1 = prediction_all[:, i][masks_all[:,i]==1]\n",
        "            a2 = labels_all[:, i][masks_all[:,i]==1]\n",
        "            try:\n",
        "                t = metric(a2.int().cpu(), a1.cpu()).item()\n",
        "            except ValueError:\n",
        "                t = 0\n",
        "            average += t\n",
        "    return average.item()/num_tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zauOzRqssFk"
      },
      "source": [
        "loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iaCrUBFCssFk"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o008N9B2ssFl"
      },
      "source": [
        "training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9JY79ZuGssFl"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UNPMgkcSssFl"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model2(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3Wj9hdXssFl"
      },
      "source": [
        "Function to compute test set score of the final saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CoaaV616ssFl"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = model2(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA6gA5bCssFl"
      },
      "source": [
        "Train the model and evaluate its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EHS_Qcn5ssFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc142ea-da48-4e65-8f53-ebe57bc70677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.232 | Valid Score: 0.553\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.553 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.158 | Valid Score: 0.643\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.643 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.150 | Valid Score: 0.713\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.713 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.147 | Valid Score: 0.732\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.732 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.144 | Valid Score: 0.746\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.746 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.143 | Valid Score: 0.748\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.748 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.143 | Valid Score: 0.750\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.750 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.142 | Valid Score: 0.755\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.755 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.141 | Valid Score: 0.756\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.756 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.140 | Valid Score: 0.762\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.762 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 11/100 | Training Loss: 0.139 | Valid Score: 0.760\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.762 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 12/100 | Training Loss: 0.140 | Valid Score: 0.753\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.762 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.139 | Valid Score: 0.763\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.763 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.137 | Valid Score: 0.764\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.137 | Valid Score: 0.764\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.136 | Valid Score: 0.768\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.768 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 17/100 | Training Loss: 0.135 | Valid Score: 0.758\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.768 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.135 | Valid Score: 0.769\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 19/100 | Training Loss: 0.135 | Valid Score: 0.767\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 0.134 | Valid Score: 0.772\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.772 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 0.133 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.773 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 22/100 | Training Loss: 0.133 | Valid Score: 0.768\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.773 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.133 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.773 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.132 | Valid Score: 0.776\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 25/100 | Training Loss: 0.132 | Valid Score: 0.767\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 26/100 | Training Loss: 0.131 | Valid Score: 0.776\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.131 | Valid Score: 0.776\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 0.131 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 0.130 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 30/100 | Training Loss: 0.130 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 31/100 | Training Loss: 0.130 | Valid Score: 0.780\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 32/100 | Training Loss: 0.130 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 0.129 | Valid Score: 0.782\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.782 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 0.129 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.782 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 35/100 | Training Loss: 0.129 | Valid Score: 0.780\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.782 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 0.128 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 37/100 | Training Loss: 0.128 | Valid Score: 0.780\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 38/100 | Training Loss: 0.128 | Valid Score: 0.782\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 39/100 | Training Loss: 0.127 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 0.127 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 41/100 | Training Loss: 0.127 | Valid Score: 0.776\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 0.126 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 0.126 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 44/100 | Training Loss: 0.126 | Valid Score: 0.782\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 0.126 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 46/100 | Training Loss: 0.126 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 0.125 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 48/100 | Training Loss: 0.126 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 49/100 | Training Loss: 0.126 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 50/100 | Training Loss: 0.125 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 0.125 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 52/100 | Training Loss: 0.124 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 53/100 | Training Loss: 0.124 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 54/100 | Training Loss: 0.123 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 55/100 | Training Loss: 0.124 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 56/100 | Training Loss: 0.123 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 57/100 | Training Loss: 0.123 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 58/100 | Training Loss: 0.123 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 59/100 | Training Loss: 0.122 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 60/100 | Training Loss: 0.122 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 61/100 | Training Loss: 0.122 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.790 \n",
            "\n",
            "Test Score: 0.735 \n",
            "\n",
            "Execution time: 702.156 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87p9rFvLpzz5"
      },
      "source": [
        "## model3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9-59jmepzz6"
      },
      "source": [
        "using graph convolutional<br>\n",
        "4 layer<br>\n",
        "no drop out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kgD-s9rMs1_K"
      },
      "outputs": [],
      "source": [
        "class model3(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv3 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv4 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VZxOgCns1_Q"
      },
      "source": [
        "Function to Compute Score of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0NKEO4nRs1_Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    metric = roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        prediction_all= torch.empty(0)\n",
        "        labels_all= torch.empty(0)\n",
        "        masks_all= torch.empty(0)\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.sigmoid(prediction)\n",
        "            prediction_all = torch.cat((prediction_all, prediction), 0)\n",
        "            labels_all = torch.cat((labels_all, labels), 0)\n",
        "            masks_all = torch.cat((masks_all, masks), 0)\n",
        "        average = torch.tensor([0.])\n",
        "        for i in range(num_tasks):\n",
        "            a1 = prediction_all[:, i][masks_all[:,i]==1]\n",
        "            a2 = labels_all[:, i][masks_all[:,i]==1]\n",
        "            try:\n",
        "                t = metric(a2.int().cpu(), a1.cpu()).item()\n",
        "            except ValueError:\n",
        "                t = 0\n",
        "            average += t\n",
        "    return average.item()/num_tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-nzUFXhs1_Q"
      },
      "source": [
        "loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "MeOOdhFms1_R"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7Eo6cl6s1_R"
      },
      "source": [
        "training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XPZHDW_0s1_R"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "86F0F8I9s1_R"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model3(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX_no56bs1_R"
      },
      "source": [
        "Function to compute test set score of the final saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "9cireNu3s1_R"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = model3(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB-1KKWEs1_R"
      },
      "source": [
        "Train the model and evaluate its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "R82j1ZEKs1_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef6efc3a-21a6-464d-83d6-5a798932b144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.215 | Valid Score: 0.558\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.558 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.154 | Valid Score: 0.662\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.662 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.149 | Valid Score: 0.712\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.712 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.145 | Valid Score: 0.736\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.736 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.143 | Valid Score: 0.747\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.747 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.141 | Valid Score: 0.749\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.749 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 7/100 | Training Loss: 0.141 | Valid Score: 0.747\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.749 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.140 | Valid Score: 0.753\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.753 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 9/100 | Training Loss: 0.139 | Valid Score: 0.752\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.753 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.139 | Valid Score: 0.754\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.754 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 11/100 | Training Loss: 0.139 | Valid Score: 0.750\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.754 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.138 | Valid Score: 0.757\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.757 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 13/100 | Training Loss: 0.138 | Valid Score: 0.755\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.757 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.137 | Valid Score: 0.760\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 15/100 | Training Loss: 0.137 | Valid Score: 0.759\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 16/100 | Training Loss: 0.136 | Valid Score: 0.758\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 17/100 | Training Loss: 0.136 | Valid Score: 0.759\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.136 | Valid Score: 0.765\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.765 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 19/100 | Training Loss: 0.135 | Valid Score: 0.761\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.765 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 20/100 | Training Loss: 0.135 | Valid Score: 0.764\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.765 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 0.134 | Valid Score: 0.765\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.765 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.134 | Valid Score: 0.766\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.766 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.133 | Valid Score: 0.767\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.767 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.133 | Valid Score: 0.768\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.768 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 25/100 | Training Loss: 0.133 | Valid Score: 0.767\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.768 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 0.133 | Valid Score: 0.772\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.772 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.132 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.773 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 0.131 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.773 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 29/100 | Training Loss: 0.131 | Valid Score: 0.766\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.773 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 30/100 | Training Loss: 0.130 | Valid Score: 0.772\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.773 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 31/100 | Training Loss: 0.130 | Valid Score: 0.770\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.773 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 32/100 | Training Loss: 0.130 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.773 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 0.129 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 0.129 | Valid Score: 0.768\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 35/100 | Training Loss: 0.129 | Valid Score: 0.775\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 36/100 | Training Loss: 0.129 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 37/100 | Training Loss: 0.128 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 38/100 | Training Loss: 0.127 | Valid Score: 0.780\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 39/100 | Training Loss: 0.127 | Valid Score: 0.778\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 0.127 | Valid Score: 0.782\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.782 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 0.127 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 42/100 | Training Loss: 0.126 | Valid Score: 0.777\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 43/100 | Training Loss: 0.126 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 44/100 | Training Loss: 0.125 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 45/100 | Training Loss: 0.125 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 46/100 | Training Loss: 0.124 | Valid Score: 0.782\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 0.124 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.788 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 48/100 | Training Loss: 0.124 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.788 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 49/100 | Training Loss: 0.124 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.788 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 0.123 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 51/100 | Training Loss: 0.123 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 52/100 | Training Loss: 0.122 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 53/100 | Training Loss: 0.122 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 54/100 | Training Loss: 0.122 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 0.122 | Valid Score: 0.793\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 0.121 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.795 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 57/100 | Training Loss: 0.122 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.796 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 58/100 | Training Loss: 0.121 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.796 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 59/100 | Training Loss: 0.121 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.796 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 60/100 | Training Loss: 0.121 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.796 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 0.120 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 62/100 | Training Loss: 0.120 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 63/100 | Training Loss: 0.119 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 0.119 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 65/100 | Training Loss: 0.119 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 66/100 | Training Loss: 0.119 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 0.118 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 0.118 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 69/100 | Training Loss: 0.118 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 0.117 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 0.118 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 0.117 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 73/100 | Training Loss: 0.117 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 74/100 | Training Loss: 0.117 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 75/100 | Training Loss: 0.116 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 76/100 | Training Loss: 0.116 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 77/100 | Training Loss: 0.115 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 78/100 | Training Loss: 0.116 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 79/100 | Training Loss: 0.115 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 80/100 | Training Loss: 0.116 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 81/100 | Training Loss: 0.115 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 82/100 | Training Loss: 0.114 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 83/100 | Training Loss: 0.115 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 84/100 | Training Loss: 0.114 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 85/100 | Training Loss: 0.115 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 86/100 | Training Loss: 0.114 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.809 \n",
            "\n",
            "Test Score: 0.765 \n",
            "\n",
            "Execution time: 1117.946 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqMi0vwiqCn3"
      },
      "source": [
        "## model4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKYgYGQrqCn4"
      },
      "source": [
        "using graph convolutional<br>\n",
        "4 layer<br>\n",
        "drop out = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "INekLd47tckQ"
      },
      "outputs": [],
      "source": [
        "class model4(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv3 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv4 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ll306fYtckV"
      },
      "source": [
        "Function to Compute Score of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qbL65VWMtckV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    metric = roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        prediction_all= torch.empty(0)\n",
        "        labels_all= torch.empty(0)\n",
        "        masks_all= torch.empty(0)\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.sigmoid(prediction)\n",
        "            prediction_all = torch.cat((prediction_all, prediction), 0)\n",
        "            labels_all = torch.cat((labels_all, labels), 0)\n",
        "            masks_all = torch.cat((masks_all, masks), 0)\n",
        "        average = torch.tensor([0.])\n",
        "        for i in range(num_tasks):\n",
        "            a1 = prediction_all[:, i][masks_all[:,i]==1]\n",
        "            a2 = labels_all[:, i][masks_all[:,i]==1]\n",
        "            try:\n",
        "                t = metric(a2.int().cpu(), a1.cpu()).item()\n",
        "            except ValueError:\n",
        "                t = 0\n",
        "            average += t\n",
        "    return average.item()/num_tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDbO8lLAtckV"
      },
      "source": [
        "loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "68_kuocttckV"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzU23JvGtckV"
      },
      "source": [
        "training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "HplDp4FGtckW"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KrtAgeentckW"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model4(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJYkGvU5tckW"
      },
      "source": [
        "Function to compute test set score of the final saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "hstWovaDtckW"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = model4(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL3WR9fFtckW"
      },
      "source": [
        "Train the model and evaluate its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "U592komCtckW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c2ab67d-37fd-458d-c01c-61c5c230ecb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.221 | Valid Score: 0.568\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.568 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.154 | Valid Score: 0.684\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.684 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.148 | Valid Score: 0.733\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.733 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.145 | Valid Score: 0.749\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.749 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 5/100 | Training Loss: 0.143 | Valid Score: 0.746\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.749 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.142 | Valid Score: 0.750\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.750 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.141 | Valid Score: 0.751\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.751 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.141 | Valid Score: 0.755\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.755 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 9/100 | Training Loss: 0.140 | Valid Score: 0.754\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.755 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.140 | Valid Score: 0.757\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.757 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.139 | Valid Score: 0.758\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.758 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 12/100 | Training Loss: 0.140 | Valid Score: 0.758\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.758 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.140 | Valid Score: 0.765\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.765 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 14/100 | Training Loss: 0.138 | Valid Score: 0.760\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.765 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 15/100 | Training Loss: 0.138 | Valid Score: 0.763\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.765 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.138 | Valid Score: 0.765\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.765 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.137 | Valid Score: 0.769\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 18/100 | Training Loss: 0.137 | Valid Score: 0.767\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.136 | Valid Score: 0.771\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.771 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 20/100 | Training Loss: 0.136 | Valid Score: 0.770\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.771 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 21/100 | Training Loss: 0.135 | Valid Score: 0.769\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.771 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.134 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.773 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.134 | Valid Score: 0.777\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.777 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 24/100 | Training Loss: 0.135 | Valid Score: 0.775\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.777 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 25/100 | Training Loss: 0.134 | Valid Score: 0.777\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.777 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 26/100 | Training Loss: 0.134 | Valid Score: 0.771\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.777 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.133 | Valid Score: 0.778\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 0.133 | Valid Score: 0.775\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 0.132 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.779 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 30/100 | Training Loss: 0.132 | Valid Score: 0.775\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.779 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 0.132 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 32/100 | Training Loss: 0.131 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 33/100 | Training Loss: 0.131 | Valid Score: 0.782\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 0.130 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 0.129 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 36/100 | Training Loss: 0.130 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 37/100 | Training Loss: 0.129 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 0.129 | Valid Score: 0.793\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 39/100 | Training Loss: 0.128 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 40/100 | Training Loss: 0.128 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 0.129 | Valid Score: 0.793\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 42/100 | Training Loss: 0.127 | Valid Score: 0.793\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 0.128 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.795 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 0.127 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 0.126 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 0.126 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 47/100 | Training Loss: 0.126 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 48/100 | Training Loss: 0.125 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 49/100 | Training Loss: 0.125 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 50/100 | Training Loss: 0.125 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 51/100 | Training Loss: 0.125 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 0.124 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 0.124 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 54/100 | Training Loss: 0.124 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 55/100 | Training Loss: 0.124 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 0.123 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 0.123 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 0.123 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 59/100 | Training Loss: 0.122 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 60/100 | Training Loss: 0.122 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 61/100 | Training Loss: 0.121 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 0.122 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 63/100 | Training Loss: 0.122 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 0.121 | Valid Score: 0.816\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.816 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 0.121 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 66/100 | Training Loss: 0.121 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 0.121 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 68/100 | Training Loss: 0.121 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 69/100 | Training Loss: 0.120 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 0.120 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 71/100 | Training Loss: 0.119 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 72/100 | Training Loss: 0.119 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 0.119 | Valid Score: 0.824\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 74/100 | Training Loss: 0.119 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 75/100 | Training Loss: 0.119 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 76/100 | Training Loss: 0.117 | Valid Score: 0.824\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 77/100 | Training Loss: 0.119 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 78/100 | Training Loss: 0.118 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 79/100 | Training Loss: 0.118 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 80/100 | Training Loss: 0.117 | Valid Score: 0.819\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 81/100 | Training Loss: 0.117 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 82/100 | Training Loss: 0.117 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 83/100 | Training Loss: 0.117 | Valid Score: 0.825\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 0.825 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 84/100 | Training Loss: 0.117 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 0.825 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 85/100 | Training Loss: 0.116 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 0.825 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 86/100 | Training Loss: 0.116 | Valid Score: 0.825\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 0.825 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 87/100 | Training Loss: 0.116 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 0.825 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 88/100 | Training Loss: 0.116 | Valid Score: 0.826\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 89/100 | Training Loss: 0.116 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 90/100 | Training Loss: 0.115 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 91/100 | Training Loss: 0.115 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 92/100 | Training Loss: 0.116 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 93/100 | Training Loss: 0.115 | Valid Score: 0.824\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 94/100 | Training Loss: 0.114 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 95/100 | Training Loss: 0.114 | Valid Score: 0.825\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 96/100 | Training Loss: 0.114 | Valid Score: 0.827\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 97/100 | Training Loss: 0.114 | Valid Score: 0.824\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 98/100 | Training Loss: 0.113 | Valid Score: 0.819\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 99/100 | Training Loss: 0.113 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 100/100 | Training Loss: 0.114 | Valid Score: 0.824\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.827 \n",
            "\n",
            "Test Score: 0.772 \n",
            "\n",
            "Execution time: 1323.309 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR5obdYhqH2T"
      },
      "source": [
        "## model5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ooqS5TqH2T"
      },
      "source": [
        "using graph convolutional<br>\n",
        "4 layer<br>\n",
        "drop out = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "wF-3Vg3PtjAK"
      },
      "outputs": [],
      "source": [
        "class model5(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv3 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv4 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXI2WSB_tjAL"
      },
      "source": [
        "Function to Compute Score of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "1Vu9ObJHtjAM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    metric = roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        prediction_all= torch.empty(0)\n",
        "        labels_all= torch.empty(0)\n",
        "        masks_all= torch.empty(0)\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.sigmoid(prediction)\n",
        "            prediction_all = torch.cat((prediction_all, prediction), 0)\n",
        "            labels_all = torch.cat((labels_all, labels), 0)\n",
        "            masks_all = torch.cat((masks_all, masks), 0)\n",
        "        average = torch.tensor([0.])\n",
        "        for i in range(num_tasks):\n",
        "            a1 = prediction_all[:, i][masks_all[:,i]==1]\n",
        "            a2 = labels_all[:, i][masks_all[:,i]==1]\n",
        "            try:\n",
        "                t = metric(a2.int().cpu(), a1.cpu()).item()\n",
        "            except ValueError:\n",
        "                t = 0\n",
        "            average += t\n",
        "    return average.item()/num_tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C-Oq6RCtjAN"
      },
      "source": [
        "loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "XK1kAdEktjAO"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZMjZ9iktjAO"
      },
      "source": [
        "training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ukJD1CX_tjAP"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "PPGk2wTDtjAP"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model5(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aMFpTYztjAP"
      },
      "source": [
        "Function to compute test set score of the final saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "29Mcn6BLtjAP"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = model5(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCZjpFdJtjAP"
      },
      "source": [
        "Train the model and evaluate its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "nXFj9phvtjAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae7efb59-180f-43a7-e0c8-4cad8fbe00d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.213 | Valid Score: 0.571\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.571 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.155 | Valid Score: 0.665\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.665 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.149 | Valid Score: 0.709\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.709 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.146 | Valid Score: 0.734\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.734 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.144 | Valid Score: 0.745\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.745 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.142 | Valid Score: 0.749\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.749 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.144 | Valid Score: 0.751\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.751 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 8/100 | Training Loss: 0.141 | Valid Score: 0.751\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.751 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.140 | Valid Score: 0.752\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.752 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.140 | Valid Score: 0.753\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.753 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.139 | Valid Score: 0.760\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.139 | Valid Score: 0.761\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.761 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 13/100 | Training Loss: 0.139 | Valid Score: 0.760\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.761 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.138 | Valid Score: 0.763\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.763 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.138 | Valid Score: 0.767\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.767 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.137 | Valid Score: 0.767\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.767 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.137 | Valid Score: 0.771\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.771 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.137 | Valid Score: 0.775\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.775 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 19/100 | Training Loss: 0.136 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.775 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 0.135 | Valid Score: 0.776\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 21/100 | Training Loss: 0.135 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 22/100 | Training Loss: 0.137 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.135 | Valid Score: 0.777\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.777 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 24/100 | Training Loss: 0.134 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.777 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 0.134 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.779 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 26/100 | Training Loss: 0.133 | Valid Score: 0.778\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.779 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.133 | Valid Score: 0.782\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.782 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 0.133 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 29/100 | Training Loss: 0.132 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 30/100 | Training Loss: 0.132 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 31/100 | Training Loss: 0.131 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 32/100 | Training Loss: 0.131 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 0.130 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 0.130 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 0.130 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.788 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 0.129 | Valid Score: 0.793\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 37/100 | Training Loss: 0.130 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 38/100 | Training Loss: 0.129 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 39/100 | Training Loss: 0.128 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 40/100 | Training Loss: 0.127 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 41/100 | Training Loss: 0.128 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 0.127 | Valid Score: 0.793\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 0.127 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.795 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 44/100 | Training Loss: 0.127 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.795 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 0.126 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 46/100 | Training Loss: 0.126 | Valid Score: 0.793\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 0.126 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 48/100 | Training Loss: 0.127 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 49/100 | Training Loss: 0.126 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 0.125 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 51/100 | Training Loss: 0.125 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 0.126 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 53/100 | Training Loss: 0.124 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 54/100 | Training Loss: 0.125 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 55/100 | Training Loss: 0.123 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 0.122 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 0.122 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 0.122 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 59/100 | Training Loss: 0.122 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 60/100 | Training Loss: 0.122 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 0.122 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 62/100 | Training Loss: 0.121 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 0.121 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 64/100 | Training Loss: 0.121 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 0.120 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 66/100 | Training Loss: 0.121 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 67/100 | Training Loss: 0.121 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 68/100 | Training Loss: 0.120 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 0.120 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 0.120 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 71/100 | Training Loss: 0.119 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 72/100 | Training Loss: 0.119 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 0.119 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 74/100 | Training Loss: 0.120 | Valid Score: 0.816\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 0.816 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 75/100 | Training Loss: 0.118 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 0.816 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 76/100 | Training Loss: 0.118 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 0.816 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 77/100 | Training Loss: 0.118 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 78/100 | Training Loss: 0.117 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 79/100 | Training Loss: 0.117 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 80/100 | Training Loss: 0.117 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 81/100 | Training Loss: 0.117 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 82/100 | Training Loss: 0.117 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 83/100 | Training Loss: 0.117 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 84/100 | Training Loss: 0.117 | Valid Score: 0.819\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 85/100 | Training Loss: 0.116 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 86/100 | Training Loss: 0.118 | Valid Score: 0.816\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 87/100 | Training Loss: 0.116 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 88/100 | Training Loss: 0.116 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 89/100 | Training Loss: 0.116 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 90/100 | Training Loss: 0.116 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 91/100 | Training Loss: 0.116 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 92/100 | Training Loss: 0.115 | Valid Score: 0.816\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 93/100 | Training Loss: 0.115 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 94/100 | Training Loss: 0.115 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 95/100 | Training Loss: 0.114 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 96/100 | Training Loss: 0.115 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 97/100 | Training Loss: 0.114 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 98/100 | Training Loss: 0.114 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 99/100 | Training Loss: 0.113 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 100/100 | Training Loss: 0.113 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.822 \n",
            "\n",
            "Test Score: 0.764 \n",
            "\n",
            "Execution time: 1251.433 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNKD0HMuqNXY"
      },
      "source": [
        "## model6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNgbpe2KqNXZ"
      },
      "source": [
        "using graph sage<br>\n",
        "4 layer<br>\n",
        "no drop out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "El3VKQTpts3L"
      },
      "outputs": [],
      "source": [
        "class model6(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.conv3 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.conv4 = SAGEConv(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnJeVyDkts3M"
      },
      "source": [
        "Function to Compute Score of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "sKg0rU_Ots3N"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    metric = roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        prediction_all= torch.empty(0)\n",
        "        labels_all= torch.empty(0)\n",
        "        masks_all= torch.empty(0)\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.sigmoid(prediction)\n",
        "            prediction_all = torch.cat((prediction_all, prediction), 0)\n",
        "            labels_all = torch.cat((labels_all, labels), 0)\n",
        "            masks_all = torch.cat((masks_all, masks), 0)\n",
        "        average = torch.tensor([0.])\n",
        "        for i in range(num_tasks):\n",
        "            a1 = prediction_all[:, i][masks_all[:,i]==1]\n",
        "            a2 = labels_all[:, i][masks_all[:,i]==1]\n",
        "            try:\n",
        "                t = metric(a2.int().cpu(), a1.cpu()).item()\n",
        "            except ValueError:\n",
        "                t = 0\n",
        "            average += t\n",
        "    return average.item()/num_tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG5MMsATts3N"
      },
      "source": [
        "loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "qqUwXJuUts3O"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQVdV11mts3O"
      },
      "source": [
        "training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "2uYwcZ9Bts3P"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "kiF9v0kHts3P"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model6(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imGeTGYLts3Q"
      },
      "source": [
        "Function to compute test set score of the final saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ZGFnl1wHts3Q"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = model6(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5TlMhgvts3Q"
      },
      "source": [
        "Train the model and evaluate its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xnKwWclLts3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238b4bc6-b089-4a90-b624-544213300afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.227 | Valid Score: 0.583\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.583 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.153 | Valid Score: 0.702\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.702 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.147 | Valid Score: 0.746\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.746 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.144 | Valid Score: 0.754\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.754 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.143 | Valid Score: 0.759\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.759 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 6/100 | Training Loss: 0.141 | Valid Score: 0.752\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.759 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.141 | Valid Score: 0.759\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.759 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.139 | Valid Score: 0.766\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.766 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.139 | Valid Score: 0.769\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.137 | Valid Score: 0.769\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.136 | Valid Score: 0.772\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.772 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.136 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.774 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.135 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 14/100 | Training Loss: 0.135 | Valid Score: 0.778\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 15/100 | Training Loss: 0.133 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 16/100 | Training Loss: 0.134 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 17/100 | Training Loss: 0.133 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 18/100 | Training Loss: 0.131 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.131 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 20/100 | Training Loss: 0.130 | Valid Score: 0.782\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 21/100 | Training Loss: 0.129 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.129 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.796 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.129 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 24/100 | Training Loss: 0.128 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 25/100 | Training Loss: 0.127 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 26/100 | Training Loss: 0.128 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.127 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 0.126 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 0.125 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 30/100 | Training Loss: 0.124 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 31/100 | Training Loss: 0.124 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 0.124 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 33/100 | Training Loss: 0.123 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 34/100 | Training Loss: 0.122 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 35/100 | Training Loss: 0.122 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 36/100 | Training Loss: 0.121 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 37/100 | Training Loss: 0.121 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 38/100 | Training Loss: 0.120 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 39/100 | Training Loss: 0.120 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 40/100 | Training Loss: 0.120 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 41/100 | Training Loss: 0.119 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 42/100 | Training Loss: 0.119 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.817 \n",
            "\n",
            "Test Score: 0.760 \n",
            "\n",
            "Execution time: 529.626 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngSyl5c9qNXi"
      },
      "source": [
        "## model7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tacXfCYhqNXi"
      },
      "source": [
        "using graph sage<br>\n",
        "4 layer<br>\n",
        "drop out = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "QGztdTrntxyf"
      },
      "outputs": [],
      "source": [
        "class model7(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.conv3 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.conv4 = SAGEConv(self.hidden_size, self.num_tasks)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tag3ur1Ytxyl"
      },
      "source": [
        "Function to Compute Score of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "vZQ8fYAQtxym"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    metric = roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        prediction_all= torch.empty(0)\n",
        "        labels_all= torch.empty(0)\n",
        "        masks_all= torch.empty(0)\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.sigmoid(prediction)\n",
        "            prediction_all = torch.cat((prediction_all, prediction), 0)\n",
        "            labels_all = torch.cat((labels_all, labels), 0)\n",
        "            masks_all = torch.cat((masks_all, masks), 0)\n",
        "        average = torch.tensor([0.])\n",
        "        for i in range(num_tasks):\n",
        "            a1 = prediction_all[:, i][masks_all[:,i]==1]\n",
        "            a2 = labels_all[:, i][masks_all[:,i]==1]\n",
        "            try:\n",
        "                t = metric(a2.int().cpu(), a1.cpu()).item()\n",
        "            except ValueError:\n",
        "                t = 0\n",
        "            average += t\n",
        "    return average.item()/num_tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agK_ABIEtxym"
      },
      "source": [
        "loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "tX8J9gA-txym"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qb7Bfiftxym"
      },
      "source": [
        "training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "SMk5L0KFtxym"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "R-jJUhJptxym"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model7(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLIKaviGtxyn"
      },
      "source": [
        "Function to compute test set score of the final saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Jpy_7bxntxyn"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = model7(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM1Lxxj3txyn"
      },
      "source": [
        "Train the model and evaluate its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "0-rn50yntxyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb409caa-9155-4f6a-aea0-711d1dc40edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.217 | Valid Score: 0.614\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.614 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.150 | Valid Score: 0.737\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.737 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.144 | Valid Score: 0.751\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.751 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.143 | Valid Score: 0.760\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 5/100 | Training Loss: 0.142 | Valid Score: 0.755\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.140 | Valid Score: 0.766\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.766 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.139 | Valid Score: 0.771\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.771 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.139 | Valid Score: 0.772\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.772 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.137 | Valid Score: 0.775\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.775 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.136 | Valid Score: 0.777\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.777 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.135 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.779 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.134 | Valid Score: 0.780\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.780 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.133 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 14/100 | Training Loss: 0.133 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 15/100 | Training Loss: 0.131 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 16/100 | Training Loss: 0.130 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.129 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.795 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.129 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.127 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 20/100 | Training Loss: 0.127 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 21/100 | Training Loss: 0.126 | Valid Score: 0.793\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.125 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 23/100 | Training Loss: 0.125 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 24/100 | Training Loss: 0.124 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 0.124 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 26/100 | Training Loss: 0.123 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 27/100 | Training Loss: 0.122 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 28/100 | Training Loss: 0.122 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 29/100 | Training Loss: 0.121 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 0.121 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 31/100 | Training Loss: 0.120 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 32/100 | Training Loss: 0.120 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 0.121 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 0.119 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 35/100 | Training Loss: 0.119 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 36/100 | Training Loss: 0.117 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 37/100 | Training Loss: 0.117 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 0.117 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.116 | Valid Score: 0.819\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.819 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 40/100 | Training Loss: 0.115 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.819 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 41/100 | Training Loss: 0.115 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.819 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 42/100 | Training Loss: 0.114 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.819 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 0.113 | Valid Score: 0.825\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.825 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 44/100 | Training Loss: 0.113 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.825 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 45/100 | Training Loss: 0.114 | Valid Score: 0.824\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.825 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 46/100 | Training Loss: 0.112 | Valid Score: 0.819\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.825 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 47/100 | Training Loss: 0.112 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.825 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 48/100 | Training Loss: 0.111 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.825 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 49/100 | Training Loss: 0.111 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.825 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 0.111 | Valid Score: 0.828\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.828 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 51/100 | Training Loss: 0.111 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.828 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 52/100 | Training Loss: 0.109 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.828 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 53/100 | Training Loss: 0.110 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.828 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 0.108 | Valid Score: 0.830\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.830 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 55/100 | Training Loss: 0.108 | Valid Score: 0.827\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.830 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 0.108 | Valid Score: 0.832\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.832 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 0.107 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.832 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 58/100 | Training Loss: 0.108 | Valid Score: 0.828\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.832 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 59/100 | Training Loss: 0.107 | Valid Score: 0.828\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.832 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 60/100 | Training Loss: 0.107 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.832 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 61/100 | Training Loss: 0.107 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.832 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 62/100 | Training Loss: 0.106 | Valid Score: 0.827\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.832 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 63/100 | Training Loss: 0.107 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.832 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 64/100 | Training Loss: 0.106 | Valid Score: 0.827\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.832 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 65/100 | Training Loss: 0.105 | Valid Score: 0.826\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.832 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 66/100 | Training Loss: 0.106 | Valid Score: 0.826\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.832 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.832 \n",
            "\n",
            "Test Score: 0.783 \n",
            "\n",
            "Execution time: 838.781 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF6eGyJwqNXj"
      },
      "source": [
        "## model8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZINqS7aqNXj"
      },
      "source": [
        "using graph sage<br>\n",
        "4 layer<br>\n",
        "drop out = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "51QPtwZht2r_"
      },
      "outputs": [],
      "source": [
        "class model8(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.conv3 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.conv4 = SAGEConv(self.hidden_size, self.num_tasks)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn7ausjVt2sE"
      },
      "source": [
        "Function to Compute Score of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "YpyVgGfRt2sE"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    metric = roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        prediction_all= torch.empty(0)\n",
        "        labels_all= torch.empty(0)\n",
        "        masks_all= torch.empty(0)\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.sigmoid(prediction)\n",
        "            prediction_all = torch.cat((prediction_all, prediction), 0)\n",
        "            labels_all = torch.cat((labels_all, labels), 0)\n",
        "            masks_all = torch.cat((masks_all, masks), 0)\n",
        "        average = torch.tensor([0.])\n",
        "        for i in range(num_tasks):\n",
        "            a1 = prediction_all[:, i][masks_all[:,i]==1]\n",
        "            a2 = labels_all[:, i][masks_all[:,i]==1]\n",
        "            try:\n",
        "                t = metric(a2.int().cpu(), a1.cpu()).item()\n",
        "            except ValueError:\n",
        "                t = 0\n",
        "            average += t\n",
        "    return average.item()/num_tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFYj7qpIt2sE"
      },
      "source": [
        "loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "7c4TdOeOt2sE"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiUaEYmkt2sE"
      },
      "source": [
        "training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "3EYMv1FWt2sE"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "EA0O_-drt2sF"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model8(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dsquqtNt2sF"
      },
      "source": [
        "Function to compute test set score of the final saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "S8GkmjDdt2sF"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = model8(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-STxAS39t2sF"
      },
      "source": [
        "Train the model and evaluate its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "jmMBMmKit2sF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae1c3439-60c9-4a01-f8fb-347bc6885d8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.214 | Valid Score: 0.598\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.598 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.152 | Valid Score: 0.713\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.713 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.147 | Valid Score: 0.738\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.738 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.145 | Valid Score: 0.738\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.738 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.144 | Valid Score: 0.747\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.747 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 6/100 | Training Loss: 0.141 | Valid Score: 0.744\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.747 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.140 | Valid Score: 0.758\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.758 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.139 | Valid Score: 0.759\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.759 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.138 | Valid Score: 0.768\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.768 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 10/100 | Training Loss: 0.137 | Valid Score: 0.768\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.768 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.135 | Valid Score: 0.776\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.134 | Valid Score: 0.776\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.133 | Valid Score: 0.780\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.780 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.132 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.131 | Valid Score: 0.793\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 16/100 | Training Loss: 0.130 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 17/100 | Training Loss: 0.129 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.128 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.794 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.128 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.795 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 0.127 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 0.126 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 22/100 | Training Loss: 0.125 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 23/100 | Training Loss: 0.125 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 24/100 | Training Loss: 0.124 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 25/100 | Training Loss: 0.123 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 26/100 | Training Loss: 0.123 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 27/100 | Training Loss: 0.122 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 0.122 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 29/100 | Training Loss: 0.120 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 30/100 | Training Loss: 0.120 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 31/100 | Training Loss: 0.119 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 0.119 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 33/100 | Training Loss: 0.119 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 0.119 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 35/100 | Training Loss: 0.118 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 36/100 | Training Loss: 0.117 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 37/100 | Training Loss: 0.118 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 38/100 | Training Loss: 0.116 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.118 | Valid Score: 0.816\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.816 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 40/100 | Training Loss: 0.116 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.816 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 41/100 | Training Loss: 0.114 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.816 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 0.115 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 43/100 | Training Loss: 0.114 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 44/100 | Training Loss: 0.116 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 45/100 | Training Loss: 0.114 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 46/100 | Training Loss: 0.113 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 47/100 | Training Loss: 0.113 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 48/100 | Training Loss: 0.112 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 0.111 | Valid Score: 0.828\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.828 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 50/100 | Training Loss: 0.112 | Valid Score: 0.816\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.828 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 51/100 | Training Loss: 0.111 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.828 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 52/100 | Training Loss: 0.111 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.828 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 53/100 | Training Loss: 0.110 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.828 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 54/100 | Training Loss: 0.110 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.828 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 0.110 | Valid Score: 0.833\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.833 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 0.109 | Valid Score: 0.833\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.833 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 0.110 | Valid Score: 0.825\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.833 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 58/100 | Training Loss: 0.111 | Valid Score: 0.833\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.833 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 59/100 | Training Loss: 0.108 | Valid Score: 0.828\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.833 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 60/100 | Training Loss: 0.108 | Valid Score: 0.826\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.833 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 61/100 | Training Loss: 0.108 | Valid Score: 0.828\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.833 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 0.108 | Valid Score: 0.837\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.837 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 63/100 | Training Loss: 0.108 | Valid Score: 0.827\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.837 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 64/100 | Training Loss: 0.107 | Valid Score: 0.833\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.837 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 65/100 | Training Loss: 0.108 | Valid Score: 0.831\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.837 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 66/100 | Training Loss: 0.107 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.837 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 67/100 | Training Loss: 0.107 | Valid Score: 0.832\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 0.837 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 68/100 | Training Loss: 0.106 | Valid Score: 0.833\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 0.837 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 69/100 | Training Loss: 0.106 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 0.837 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 70/100 | Training Loss: 0.105 | Valid Score: 0.832\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 0.837 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 0.106 | Valid Score: 0.839\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 0.839 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 72/100 | Training Loss: 0.105 | Valid Score: 0.831\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 0.839 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 73/100 | Training Loss: 0.108 | Valid Score: 0.825\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 0.839 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 74/100 | Training Loss: 0.106 | Valid Score: 0.834\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 0.839 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 0.105 | Valid Score: 0.842\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 0.842 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 76/100 | Training Loss: 0.104 | Valid Score: 0.843\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 77/100 | Training Loss: 0.104 | Valid Score: 0.843\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 78/100 | Training Loss: 0.103 | Valid Score: 0.835\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 79/100 | Training Loss: 0.103 | Valid Score: 0.833\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 80/100 | Training Loss: 0.103 | Valid Score: 0.840\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 81/100 | Training Loss: 0.103 | Valid Score: 0.828\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 82/100 | Training Loss: 0.102 | Valid Score: 0.840\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 83/100 | Training Loss: 0.104 | Valid Score: 0.830\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 84/100 | Training Loss: 0.103 | Valid Score: 0.837\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 85/100 | Training Loss: 0.103 | Valid Score: 0.837\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 86/100 | Training Loss: 0.102 | Valid Score: 0.843\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.843 \n",
            "\n",
            "Test Score: 0.782 \n",
            "\n",
            "Execution time: 1094.284 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}