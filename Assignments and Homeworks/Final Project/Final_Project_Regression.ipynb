{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "pMreSOobNpmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## adding necessary tools"
      ],
      "metadata": {
        "id": "rKC8IJrOP0uR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAEGGdr8NiMp",
        "outputId": "01c8ea19-cf71-43cc-da3e-80f188269d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n"
          ]
        }
      ],
      "source": [
        "#installing deep graph library\n",
        "!pip3 install dgl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dglgo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaxp1R-jNsJU",
        "outputId": "a3dd0767-737d-4241-d268-5a078fc1210c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dglgo in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.7.0)\n",
            "Requirement already satisfied: isort>=5.10.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (5.12.0)\n",
            "Requirement already satisfied: autopep8>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (2.0.2)\n",
            "Requirement already satisfied: numpydoc>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.5.0)\n",
            "Requirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.10.9)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.20 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.17.32)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0)\n",
            "Requirement already satisfied: ogb>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.3.6)\n",
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.10/dist-packages (from dglgo) (2022.9.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n",
            "Requirement already satisfied: pycodestyle>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.10.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinx>=4.2 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (7.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.65.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.26.16)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (0.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.6.3)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.20->dglgo) (0.2.7)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
            "Requirement already satisfied: docutils<0.21,>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.20.1)\n",
            "Requirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (16.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import os #to create and dealing with directory\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl #deep graph library\n",
        "import numpy as np #numerical functions\n",
        "import networkx as nx #to represent graph and dealing with graph\n",
        "import torch #for neural network\n",
        "import torch.nn as nn\n",
        "import dgl.function as fn #to catch functions\n",
        "import torch.nn.functional as F #neural network functions\n",
        "import shutil #help us import dataset\n",
        "from torch.utils.data import DataLoader #to load data\n",
        "import cloudpickle\n",
        "from dgl.nn import GraphConv\n",
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "zZnQdqcRNsNK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loading dataset"
      ],
      "metadata": {
        "id": "rxUhqS2JP4rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using ESOL dataset.<br>\n",
        "ESOL is a small dataset consisting of water solubility data for some compounds."
      ],
      "metadata": {
        "id": "PdbNT7JTQfc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "current_dir = \"./\"\n",
        "checkpoint_path = current_dir + \"save_models/model_checkpoints/\" + \"checkpoint\"\n",
        "os.makedirs(checkpoint_path, exist_ok=True)\n",
        "\n",
        "best_model_path = current_dir + \"save_models/best_model/\"\n",
        "\n",
        "folder_data_temp = current_dir +\"data_temp/\"\n",
        "shutil.rmtree(folder_data_temp, ignore_errors=True)\n",
        "\n",
        "path_save = current_dir + \"graph_regression.zip\"\n",
        "shutil.unpack_archive(path_save, folder_data_temp)"
      ],
      "metadata": {
        "id": "61_AUdRuP8Ge"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a custom pytorch regression dataset class"
      ],
      "metadata": {
        "id": "ykUmYbHERB6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Regression Dataset \"\"\"\n",
        "class DGLDatasetReg(torch.utils.data.Dataset):\n",
        "    def __init__(self, address, transform=None, train=False, scaler=None, scaler_regression=None):\n",
        "            self.train = train\n",
        "            self.scaler = scaler\n",
        "            self.data_set, train_labels_masks_globals = dgl.load_graphs(address+\".bin\")\n",
        "            num_graphs = len(self.data_set)\n",
        "            self.labels = train_labels_masks_globals[\"labels\"].view(num_graphs,-1)\n",
        "            self.masks = train_labels_masks_globals[\"masks\"].view(num_graphs,-1)\n",
        "            self.globals = train_labels_masks_globals[\"globals\"].view(num_graphs,-1)\n",
        "            self.transform = transform\n",
        "            self.scaler_regression = scaler_regression\n",
        "    def scaler_method(self):\n",
        "        if self.train:\n",
        "            scaler = preprocessing.StandardScaler().fit(self.labels)\n",
        "            self.scaler = scaler\n",
        "        return self.scaler\n",
        "    def __len__(self):\n",
        "        return len(self.data_set)\n",
        "    def __getitem__(self, idx):\n",
        "        if self.scaler_regression:\n",
        "            \"\"\" With Scaler\"\"\"\n",
        "            return  self.data_set[idx], torch.tensor(self.scaler.transform(self.labels)[idx]).float(), self.masks[idx], self.globals[idx]\n",
        "        else:\n",
        "            \"\"\" Without Scaler \"\"\"\n",
        "            return  self.data_set[idx], self.labels[idx].float(), self.masks[idx], self.globals[idx]"
      ],
      "metadata": {
        "id": "Bxa4pX8GRQYG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "performing train and test and split according to file"
      ],
      "metadata": {
        "id": "FEg8g8fqTKe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_data_temp = folder_data_temp + \"scaffold\"+\"_\"+str(0)\n",
        "\n",
        "train_set = DGLDatasetReg(address=path_data_temp+\"_train\")\n",
        "scaler= train_set.scaler_method()\n",
        "val_set = DGLDatasetReg(address=path_data_temp+\"_val\", scaler = scaler)\n",
        "test_set = DGLDatasetReg(address=path_data_temp+\"_test\", scaler = scaler)\n",
        "\n",
        "print(len(train_set), len(val_set), len(test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9Xg2azYbN4p",
        "outputId": "5dbfa035-952b-41fb-c04a-f3389b20c611"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "902 112 114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(batch):\n",
        "    # batch is a list of tuples (graphs, labels, masks, globals)\n",
        "    # Concatenate a sequence of graphs\n",
        "    graphs = [e[0] for e in batch]\n",
        "    g = dgl.batch(graphs)\n",
        "\n",
        "    # Concatenate a sequence of tensors (labels) along a new dimension\n",
        "    labels = [e[1] for e in batch]\n",
        "    labels = torch.stack(labels, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (masks) along a new dimension\n",
        "    masks = [e[2] for e in batch]\n",
        "    masks = torch.stack(masks, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (globals) along a new dimension\n",
        "    globals = [e[3] for e in batch]\n",
        "    globals = torch.stack(globals, 0)\n",
        "\n",
        "    return g, labels, masks, globals\n",
        "\n",
        "def loader(batch_size = 128):\n",
        "    train_dataloader = DataLoader(train_set,\n",
        "                              batch_size=batch_size,\n",
        "                              collate_fn=collate,\n",
        "                              drop_last=False,\n",
        "                              shuffle=True,\n",
        "                              num_workers=1)\n",
        "\n",
        "    val_dataloader =  DataLoader(val_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "\n",
        "    test_dataloader = DataLoader(test_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "wfn63FcSR3-2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, val_dataloader, test_dataloader = loader(batch_size=128)"
      ],
      "metadata": {
        "id": "5o92dE7egYgs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Defining"
      ],
      "metadata": {
        "id": "zM23CcO6hamR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ESOL has only 1 task\n",
        "num_tasks = 1\n",
        "\n",
        "# Size of global feature of each graph\n",
        "global_size = 200\n",
        "\n",
        "# Number of epochs to train the model\n",
        "num_epochs = 100\n",
        "\n",
        "# Number of steps to wait if the model performance on the validation set does not improve\n",
        "patience = 10\n",
        "\n",
        "#Configurations to instantiate the model\n",
        "config = {\"node_feature_size\":127, \"edge_feature_size\":12, \"hidden_size\":100}"
      ],
      "metadata": {
        "id": "9BUkxUbnha93"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for this project we'll use 8 models"
      ],
      "metadata": {
        "id": "vByeYIVgpN2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model1"
      ],
      "metadata": {
        "id": "d4HSkQEPpRoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using graph convolutional<br>\n",
        "3 layer<br>\n",
        "no drop out"
      ],
      "metadata": {
        "id": "_VGE7xjtpUAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class model1(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv3 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "CRIlI66qpPE6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Compute Score of the Model"
      ],
      "metadata": {
        "id": "0ZCQWj_5rzrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "r1Cb-ZclRLZk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "      prediction = model(mol_dgl_graph, globals)\n",
        "      loss = loss_sum(prediction, labels)\n",
        "      final_loss += loss.item()\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "  return final_loss / num_tasks"
      ],
      "metadata": {
        "id": "L84y2qNbK7hC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss function"
      ],
      "metadata": {
        "id": "eOXDLkjurxTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "  pos_weight = torch.ones((1, num_tasks))\n",
        "  pos_weight\n",
        "  criterion = nn.MSELoss(reduction='none')\n",
        "  loss = mask*criterion(output,label)\n",
        "  loss = loss.sum() / mask.sum()\n",
        "  return loss"
      ],
      "metadata": {
        "id": "pgXJIwczrtr_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training function"
      ],
      "metadata": {
        "id": "x303YlhDr72Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ],
      "metadata": {
        "id": "ClOv1nfSr9IM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model1(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = float('inf')\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ],
      "metadata": {
        "id": "ZJ2UVWvCsFZS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compute test set score of the final saved model"
      ],
      "metadata": {
        "id": "5W_tVxDbsOof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_evaluate():\n",
        "    final_model = model1(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(val_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ],
      "metadata": {
        "id": "N8-bJXRusO8W"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model and evaluate its performance"
      ],
      "metadata": {
        "id": "xkiVFlansbSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "id": "EgdJPui8sbqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9528bd5-a909-4d0b-93cd-7cbf9f7fafe3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 13.033 | Valid Score: 4.394\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 4.394 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 12.989 | Valid Score: 4.300\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 4.300 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 11.709 | Valid Score: 4.210\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 4.210 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 9.988 | Valid Score: 4.123\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 4.123 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 12.350 | Valid Score: 4.042\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 4.042 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 9.061 | Valid Score: 3.963\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 3.963 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 9.181 | Valid Score: 3.885\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 3.885 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 8.500 | Valid Score: 3.807\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 3.807 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 9.091 | Valid Score: 3.731\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 3.731 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 7.589 | Valid Score: 3.652\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 3.652 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 7.974 | Valid Score: 3.583\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 3.583 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 6.896 | Valid Score: 3.512\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 3.512 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 7.685 | Valid Score: 3.449\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 3.449 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 6.975 | Valid Score: 3.387\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 3.387 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 6.981 | Valid Score: 3.329\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 3.329 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 6.250 | Valid Score: 3.275\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 3.275 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 5.671 | Valid Score: 3.229\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 3.229 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 6.858 | Valid Score: 3.190\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 3.190 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 6.893 | Valid Score: 3.156\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 3.156 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 7.184 | Valid Score: 3.132\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 3.132 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 5.782 | Valid Score: 3.117\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 3.117 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 5.749 | Valid Score: 3.099\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 3.099 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 6.520 | Valid Score: 3.094\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 3.094 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 6.383 | Valid Score: 3.092\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 3.092 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 6.220 | Valid Score: 3.083\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 3.083 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 6.342 | Valid Score: 3.067\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 3.067 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 6.652 | Valid Score: 3.049\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 3.049 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 5.425 | Valid Score: 3.039\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 3.039 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 5.569 | Valid Score: 3.033\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 3.033 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 6.241 | Valid Score: 3.027\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 3.027 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 6.449 | Valid Score: 3.017\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 3.017 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 32/100 | Training Loss: 5.942 | Valid Score: 3.029\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 3.017 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 33/100 | Training Loss: 5.711 | Valid Score: 3.039\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 3.017 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 34/100 | Training Loss: 5.274 | Valid Score: 3.034\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 3.017 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 35/100 | Training Loss: 5.520 | Valid Score: 3.025\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 3.017 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 36/100 | Training Loss: 6.455 | Valid Score: 3.018\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 3.017 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 37/100 | Training Loss: 5.223 | Valid Score: 3.033\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 3.017 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 38/100 | Training Loss: 5.726 | Valid Score: 3.040\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 3.017 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 39/100 | Training Loss: 5.719 | Valid Score: 3.039\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 3.017 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 40/100 | Training Loss: 5.237 | Valid Score: 3.033\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 3.017 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 41/100 | Training Loss: 5.018 | Valid Score: 3.021\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 3.017 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 3.017 \n",
            "\n",
            "Test Score: 4.354 \n",
            "\n",
            "Execution time: 34.514 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model2"
      ],
      "metadata": {
        "id": "NmijM11nptgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using graph sage<br>\n",
        "3 layer<br>\n",
        "no drop out"
      ],
      "metadata": {
        "id": "GNlFSJP4ptgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining Graph sage class from scratch\n",
        "class SAGEConv(nn.Module):\n",
        "    \"\"\"Graph convolution module used by the GraphSAGE model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_feat : int\n",
        "        Input feature size.\n",
        "    out_feat : int\n",
        "        Output feature size.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv, self).__init__()\n",
        "        # A linear submodule for projecting the input and neighbor feature to the output.\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        \"\"\"Forward computation\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        g : Graph\n",
        "            The input graph.\n",
        "        h : Tensor\n",
        "            The input node feature.\n",
        "        \"\"\"\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            # update_all is a message passing API.\n",
        "            g.update_all(\n",
        "                message_func=fn.copy_u(\"h\", \"m\"),\n",
        "                reduce_func=fn.mean(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "jCrtySVMuz0z"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class model2(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.conv3 = SAGEConv(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "-12ADlyvssFb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Compute Score of the Model"
      ],
      "metadata": {
        "id": "KwjFz83HssFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "      prediction = model(mol_dgl_graph, globals)\n",
        "      loss = loss_sum(prediction, labels)\n",
        "      final_loss += loss.item()\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "  return final_loss / num_tasks"
      ],
      "metadata": {
        "id": "nK08kHp2ssFk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss function"
      ],
      "metadata": {
        "id": "4zauOzRqssFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "iaCrUBFCssFk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training function"
      ],
      "metadata": {
        "id": "o008N9B2ssFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ],
      "metadata": {
        "id": "9JY79ZuGssFl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model2(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = float('inf')\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ],
      "metadata": {
        "id": "UNPMgkcSssFl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compute test set score of the final saved model"
      ],
      "metadata": {
        "id": "Y3Wj9hdXssFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_evaluate():\n",
        "    final_model = model2(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(val_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ],
      "metadata": {
        "id": "CoaaV616ssFl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model and evaluate its performance"
      ],
      "metadata": {
        "id": "MA6gA5bCssFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "id": "EHS_Qcn5ssFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d68e6441-e5ca-4769-e8a2-fcb356663c1e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 10.622 | Valid Score: 4.129\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 4.129 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 9.491 | Valid Score: 4.076\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 4.076 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 9.477 | Valid Score: 4.017\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 4.017 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 9.247 | Valid Score: 3.948\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 3.948 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 9.410 | Valid Score: 3.864\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 3.864 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 8.242 | Valid Score: 3.763\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 3.763 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 7.377 | Valid Score: 3.647\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 3.647 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 7.169 | Valid Score: 3.518\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 3.518 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 7.236 | Valid Score: 3.378\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 3.378 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 6.958 | Valid Score: 3.239\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 3.239 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 5.719 | Valid Score: 3.116\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 3.116 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 5.335 | Valid Score: 3.028\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 3.028 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 5.723 | Valid Score: 2.975\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 2.975 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 5.692 | Valid Score: 2.963\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 2.963 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 15/100 | Training Loss: 5.453 | Valid Score: 2.965\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 2.963 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 5.336 | Valid Score: 2.961\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 2.961 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 17/100 | Training Loss: 5.402 | Valid Score: 2.971\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 2.961 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 4.992 | Valid Score: 2.961\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 2.961 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 4.958 | Valid Score: 2.946\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 2.946 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 5.603 | Valid Score: 2.921\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 2.921 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 5.165 | Valid Score: 2.897\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 2.897 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 22/100 | Training Loss: 5.333 | Valid Score: 2.902\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 2.897 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 23/100 | Training Loss: 4.809 | Valid Score: 2.898\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 2.897 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 4.999 | Valid Score: 2.887\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 2.887 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 5.639 | Valid Score: 2.868\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 2.868 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 5.493 | Valid Score: 2.841\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 2.841 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 5.214 | Valid Score: 2.826\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 2.826 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 5.816 | Valid Score: 2.834\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 2.826 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 4.756 | Valid Score: 2.825\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 2.825 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 4.539 | Valid Score: 2.823\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 2.823 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 31/100 | Training Loss: 4.829 | Valid Score: 2.827\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 2.823 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 32/100 | Training Loss: 5.612 | Valid Score: 2.825\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 2.823 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 4.381 | Valid Score: 2.812\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 2.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 4.533 | Valid Score: 2.787\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 2.787 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 4.520 | Valid Score: 2.761\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 2.761 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 5.548 | Valid Score: 2.736\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 2.736 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 4.533 | Valid Score: 2.716\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 2.716 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 4.116 | Valid Score: 2.686\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 2.686 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 39/100 | Training Loss: 4.529 | Valid Score: 2.688\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 2.686 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 40/100 | Training Loss: 4.928 | Valid Score: 2.698\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 2.686 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 4.361 | Valid Score: 2.677\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 2.677 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 4.059 | Valid Score: 2.656\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 2.656 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 5.404 | Valid Score: 2.655\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 2.655 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 4.381 | Valid Score: 2.640\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 2.640 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 4.096 | Valid Score: 2.634\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 2.634 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 5.232 | Valid Score: 2.619\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 2.619 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 47/100 | Training Loss: 4.811 | Valid Score: 2.632\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 2.619 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 4.782 | Valid Score: 2.605\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 2.605 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 4.101 | Valid Score: 2.578\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 2.578 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 3.743 | Valid Score: 2.565\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 2.565 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 3.606 | Valid Score: 2.564\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 2.564 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 52/100 | Training Loss: 3.601 | Valid Score: 2.568\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 2.564 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 53/100 | Training Loss: 3.754 | Valid Score: 2.576\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 2.564 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 3.663 | Valid Score: 2.542\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 2.542 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 4.701 | Valid Score: 2.510\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 2.510 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 3.399 | Valid Score: 2.482\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 2.482 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 3.762 | Valid Score: 2.500\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 2.482 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 58/100 | Training Loss: 3.497 | Valid Score: 2.536\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 2.482 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 59/100 | Training Loss: 3.794 | Valid Score: 2.496\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 2.482 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 4.344 | Valid Score: 2.451\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 2.451 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 61/100 | Training Loss: 3.413 | Valid Score: 2.454\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 2.451 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 62/100 | Training Loss: 3.333 | Valid Score: 2.482\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 2.451 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 63/100 | Training Loss: 3.410 | Valid Score: 2.461\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 2.451 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 3.270 | Valid Score: 2.425\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 2.425 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 3.330 | Valid Score: 2.413\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 2.413 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 66/100 | Training Loss: 3.565 | Valid Score: 2.440\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 2.413 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 67/100 | Training Loss: 3.400 | Valid Score: 2.480\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 2.413 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 68/100 | Training Loss: 3.438 | Valid Score: 2.474\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 2.413 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 3.414 | Valid Score: 2.403\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 2.403 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 3.187 | Valid Score: 2.366\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 2.366 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 71/100 | Training Loss: 3.333 | Valid Score: 2.388\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 2.366 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 72/100 | Training Loss: 3.358 | Valid Score: 2.440\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 2.366 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 73/100 | Training Loss: 4.371 | Valid Score: 2.444\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 2.366 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 74/100 | Training Loss: 3.447 | Valid Score: 2.412\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 2.366 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 3.370 | Valid Score: 2.355\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 2.355 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 76/100 | Training Loss: 3.198 | Valid Score: 2.321\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 2.321 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 77/100 | Training Loss: 3.046 | Valid Score: 2.341\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 2.321 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 78/100 | Training Loss: 3.402 | Valid Score: 2.362\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 2.321 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 79/100 | Training Loss: 3.175 | Valid Score: 2.349\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 2.321 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 80/100 | Training Loss: 2.964 | Valid Score: 2.339\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 2.321 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 81/100 | Training Loss: 3.173 | Valid Score: 2.338\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 2.321 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 82/100 | Training Loss: 3.162 | Valid Score: 2.327\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 2.321 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 83/100 | Training Loss: 2.926 | Valid Score: 2.304\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 2.304 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 84/100 | Training Loss: 3.056 | Valid Score: 2.297\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 2.297 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 85/100 | Training Loss: 3.396 | Valid Score: 2.316\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 2.297 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 86/100 | Training Loss: 3.472 | Valid Score: 2.320\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 2.297 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 3.055 | Valid Score: 2.293\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 2.293 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 88/100 | Training Loss: 3.226 | Valid Score: 2.299\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 2.293 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 3.322 | Valid Score: 2.282\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 2.282 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 90/100 | Training Loss: 3.009 | Valid Score: 2.314\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 2.282 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 91/100 | Training Loss: 2.942 | Valid Score: 2.255\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 2.255 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 92/100 | Training Loss: 3.464 | Valid Score: 2.219\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 2.219 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 93/100 | Training Loss: 3.118 | Valid Score: 2.231\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 2.219 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 94/100 | Training Loss: 2.975 | Valid Score: 2.289\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 2.219 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 95/100 | Training Loss: 2.970 | Valid Score: 2.229\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 2.219 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 96/100 | Training Loss: 3.736 | Valid Score: 2.177\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 2.177 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 97/100 | Training Loss: 2.950 | Valid Score: 2.152\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 2.152 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 98/100 | Training Loss: 3.204 | Valid Score: 2.203\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 2.152 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 99/100 | Training Loss: 3.116 | Valid Score: 2.216\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 2.152 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 100/100 | Training Loss: 2.751 | Valid Score: 2.182\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 2.152 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 2.152 \n",
            "\n",
            "Test Score: 2.570 \n",
            "\n",
            "Execution time: 47.582 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model3"
      ],
      "metadata": {
        "id": "87p9rFvLpzz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using graph convolutional<br>\n",
        "4 layer<br>\n",
        "no drop out"
      ],
      "metadata": {
        "id": "n9-59jmepzz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class model3(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv3 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv4 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "kgD-s9rMs1_K"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Compute Score of the Model"
      ],
      "metadata": {
        "id": "9VZxOgCns1_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "      prediction = model(mol_dgl_graph, globals)\n",
        "      loss = loss_sum(prediction, labels)\n",
        "      final_loss += loss.item()\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "  return final_loss / num_tasks"
      ],
      "metadata": {
        "id": "0NKEO4nRs1_Q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss function"
      ],
      "metadata": {
        "id": "A-nzUFXhs1_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "MeOOdhFms1_R"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training function"
      ],
      "metadata": {
        "id": "j7Eo6cl6s1_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ],
      "metadata": {
        "id": "XPZHDW_0s1_R"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model3(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = float('inf')\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ],
      "metadata": {
        "id": "86F0F8I9s1_R"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compute test set score of the final saved model"
      ],
      "metadata": {
        "id": "UX_no56bs1_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_evaluate():\n",
        "    final_model = model3(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(val_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ],
      "metadata": {
        "id": "9cireNu3s1_R"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model and evaluate its performance"
      ],
      "metadata": {
        "id": "hB-1KKWEs1_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "id": "R82j1ZEKs1_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "340d0239-5032-45c0-9ce5-1c67b2809e6a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 10.142 | Valid Score: 4.125\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 4.125 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 9.370 | Valid Score: 4.043\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 4.043 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 9.737 | Valid Score: 3.962\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 3.962 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 8.967 | Valid Score: 3.876\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 3.876 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 8.759 | Valid Score: 3.788\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 3.788 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 8.174 | Valid Score: 3.691\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 3.691 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 7.985 | Valid Score: 3.584\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 3.584 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 6.900 | Valid Score: 3.475\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 3.475 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 7.813 | Valid Score: 3.368\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 3.368 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 6.406 | Valid Score: 3.273\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 3.273 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 7.415 | Valid Score: 3.199\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 3.199 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 5.964 | Valid Score: 3.129\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 3.129 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 6.789 | Valid Score: 3.069\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 3.069 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 6.103 | Valid Score: 3.024\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 3.024 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 5.498 | Valid Score: 3.006\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 3.006 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 6.014 | Valid Score: 2.998\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 2.998 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 17/100 | Training Loss: 5.537 | Valid Score: 3.007\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 2.998 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 18/100 | Training Loss: 7.642 | Valid Score: 3.005\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 2.998 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 19/100 | Training Loss: 5.300 | Valid Score: 3.005\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 2.998 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 20/100 | Training Loss: 5.489 | Valid Score: 2.999\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 2.998 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 5.629 | Valid Score: 2.984\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 2.984 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 6.762 | Valid Score: 2.977\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 2.977 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 23/100 | Training Loss: 5.283 | Valid Score: 2.993\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 2.977 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 24/100 | Training Loss: 5.137 | Valid Score: 2.987\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 2.977 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 5.567 | Valid Score: 2.972\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 2.972 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 5.258 | Valid Score: 2.962\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 2.962 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 6.556 | Valid Score: 2.956\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 2.956 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 5.352 | Valid Score: 2.935\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 2.935 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 4.876 | Valid Score: 2.928\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 2.928 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 30/100 | Training Loss: 5.422 | Valid Score: 2.931\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 2.928 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 31/100 | Training Loss: 4.955 | Valid Score: 2.930\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 2.928 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 5.648 | Valid Score: 2.926\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 2.926 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 5.146 | Valid Score: 2.924\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 2.924 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 4.809 | Valid Score: 2.951\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 2.924 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 35/100 | Training Loss: 4.890 | Valid Score: 2.943\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 2.924 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 36/100 | Training Loss: 4.928 | Valid Score: 2.929\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 2.924 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 4.813 | Valid Score: 2.919\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 2.919 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 38/100 | Training Loss: 5.036 | Valid Score: 2.920\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 2.919 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 4.995 | Valid Score: 2.899\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 2.899 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 40/100 | Training Loss: 4.697 | Valid Score: 2.900\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 2.899 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 41/100 | Training Loss: 5.131 | Valid Score: 2.915\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 2.899 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 42/100 | Training Loss: 4.561 | Valid Score: 2.919\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 2.899 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 43/100 | Training Loss: 5.740 | Valid Score: 2.905\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 2.899 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 4.667 | Valid Score: 2.870\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 2.870 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 4.929 | Valid Score: 2.861\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 2.861 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 4.801 | Valid Score: 2.856\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 2.856 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 47/100 | Training Loss: 5.308 | Valid Score: 2.872\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 2.856 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 48/100 | Training Loss: 4.869 | Valid Score: 2.892\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 2.856 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 49/100 | Training Loss: 4.400 | Valid Score: 2.878\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 2.856 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 50/100 | Training Loss: 4.387 | Valid Score: 2.879\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 2.856 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 51/100 | Training Loss: 4.620 | Valid Score: 2.868\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 2.856 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 52/100 | Training Loss: 5.466 | Valid Score: 2.884\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 2.856 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 53/100 | Training Loss: 4.340 | Valid Score: 2.876\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 2.856 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 4.380 | Valid Score: 2.850\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 2.850 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 4.696 | Valid Score: 2.835\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 2.835 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 56/100 | Training Loss: 4.899 | Valid Score: 2.846\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 2.835 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 57/100 | Training Loss: 4.243 | Valid Score: 2.863\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 2.835 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 58/100 | Training Loss: 4.304 | Valid Score: 2.868\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 2.835 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 59/100 | Training Loss: 4.241 | Valid Score: 2.871\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 2.835 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 60/100 | Training Loss: 4.552 | Valid Score: 2.853\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 2.835 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 61/100 | Training Loss: 4.605 | Valid Score: 2.842\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 2.835 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 4.278 | Valid Score: 2.830\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 2.830 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 63/100 | Training Loss: 4.720 | Valid Score: 2.830\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 2.830 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 64/100 | Training Loss: 4.162 | Valid Score: 2.846\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 2.830 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 65/100 | Training Loss: 4.553 | Valid Score: 2.857\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 2.830 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 66/100 | Training Loss: 4.691 | Valid Score: 2.832\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 2.830 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 67/100 | Training Loss: 4.567 | Valid Score: 2.868\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 2.830 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 68/100 | Training Loss: 4.386 | Valid Score: 2.862\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 2.830 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 69/100 | Training Loss: 4.575 | Valid Score: 2.865\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 2.830 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 70/100 | Training Loss: 4.557 | Valid Score: 2.846\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 2.830 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 4.189 | Valid Score: 2.814\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 2.814 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 4.508 | Valid Score: 2.799\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 2.799 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 73/100 | Training Loss: 4.497 | Valid Score: 2.822\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 2.799 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 74/100 | Training Loss: 4.314 | Valid Score: 2.816\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 2.799 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 75/100 | Training Loss: 4.065 | Valid Score: 2.826\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 2.799 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 76/100 | Training Loss: 4.102 | Valid Score: 2.829\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 2.799 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 77/100 | Training Loss: 5.266 | Valid Score: 2.810\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 2.799 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 5.649 | Valid Score: 2.771\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 2.771 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 79/100 | Training Loss: 4.189 | Valid Score: 2.772\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 2.771 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 80/100 | Training Loss: 4.131 | Valid Score: 2.817\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 2.771 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 81/100 | Training Loss: 5.806 | Valid Score: 2.846\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 2.771 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 82/100 | Training Loss: 4.541 | Valid Score: 2.829\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 2.771 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 83/100 | Training Loss: 4.418 | Valid Score: 2.806\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 2.771 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 84/100 | Training Loss: 4.792 | Valid Score: 2.821\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 2.771 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 85/100 | Training Loss: 5.709 | Valid Score: 2.831\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 2.771 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 86/100 | Training Loss: 4.372 | Valid Score: 2.813\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 2.771 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 87/100 | Training Loss: 4.432 | Valid Score: 2.799\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 2.771 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 88/100 | Training Loss: 6.129 | Valid Score: 2.804\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 2.771 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 2.771 \n",
            "\n",
            "Test Score: 3.203 \n",
            "\n",
            "Execution time: 42.800 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model4"
      ],
      "metadata": {
        "id": "KqMi0vwiqCn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using graph convolutional<br>\n",
        "4 layer<br>\n",
        "drop out = 0.1"
      ],
      "metadata": {
        "id": "sKYgYGQrqCn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class model4(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv3 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv4 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "INekLd47tckQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Compute Score of the Model"
      ],
      "metadata": {
        "id": "3ll306fYtckV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "      prediction = model(mol_dgl_graph, globals)\n",
        "      loss = loss_sum(prediction, labels)\n",
        "      final_loss += loss.item()\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "  return final_loss / num_tasks"
      ],
      "metadata": {
        "id": "qbL65VWMtckV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss function"
      ],
      "metadata": {
        "id": "YDbO8lLAtckV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "68_kuocttckV"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training function"
      ],
      "metadata": {
        "id": "CzU23JvGtckV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ],
      "metadata": {
        "id": "HplDp4FGtckW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model4(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = float('inf')\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ],
      "metadata": {
        "id": "KrtAgeentckW"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compute test set score of the final saved model"
      ],
      "metadata": {
        "id": "mJYkGvU5tckW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_evaluate():\n",
        "    final_model = model4(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(val_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ],
      "metadata": {
        "id": "hstWovaDtckW"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model and evaluate its performance"
      ],
      "metadata": {
        "id": "FL3WR9fFtckW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "id": "U592komCtckW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6440f3a9-00d8-4ed4-e23f-a707d0cb8377"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 10.175 | Valid Score: 4.077\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 4.077 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 9.419 | Valid Score: 4.014\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 4.014 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 8.645 | Valid Score: 3.949\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 3.949 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 9.077 | Valid Score: 3.881\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 3.881 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 8.337 | Valid Score: 3.804\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 3.804 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 9.771 | Valid Score: 3.721\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 3.721 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 7.581 | Valid Score: 3.630\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 3.630 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 8.713 | Valid Score: 3.531\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 3.531 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 7.490 | Valid Score: 3.425\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 3.425 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 6.659 | Valid Score: 3.321\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 3.321 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 5.990 | Valid Score: 3.233\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 3.233 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 5.910 | Valid Score: 3.152\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 3.152 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 5.413 | Valid Score: 3.088\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 3.088 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 5.691 | Valid Score: 3.039\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 3.039 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 6.062 | Valid Score: 3.003\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 3.003 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 6.265 | Valid Score: 2.977\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 2.977 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 5.497 | Valid Score: 2.955\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 2.955 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 18/100 | Training Loss: 5.693 | Valid Score: 2.960\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 2.955 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 19/100 | Training Loss: 5.608 | Valid Score: 2.970\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 2.955 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 20/100 | Training Loss: 6.790 | Valid Score: 2.969\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 2.955 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 21/100 | Training Loss: 5.059 | Valid Score: 2.961\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 2.955 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 5.234 | Valid Score: 2.951\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 2.951 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 5.277 | Valid Score: 2.951\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 2.951 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 24/100 | Training Loss: 4.981 | Valid Score: 2.962\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 2.951 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 25/100 | Training Loss: 5.237 | Valid Score: 2.958\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 2.951 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 5.364 | Valid Score: 2.950\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 2.950 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 27/100 | Training Loss: 5.496 | Valid Score: 2.951\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 2.950 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 5.473 | Valid Score: 2.948\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 2.948 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 4.934 | Valid Score: 2.938\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 2.938 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 5.091 | Valid Score: 2.926\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 2.926 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 5.038 | Valid Score: 2.920\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 2.920 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 5.353 | Valid Score: 2.912\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 2.912 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 4.902 | Valid Score: 2.911\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 2.911 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 4.966 | Valid Score: 2.913\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 2.911 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 4.808 | Valid Score: 2.910\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 2.910 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 5.123 | Valid Score: 2.905\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 2.905 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 4.778 | Valid Score: 2.903\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 2.903 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 38/100 | Training Loss: 4.642 | Valid Score: 2.904\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 2.903 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 4.693 | Valid Score: 2.896\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 2.896 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 40/100 | Training Loss: 4.651 | Valid Score: 2.901\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 2.896 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 41/100 | Training Loss: 4.780 | Valid Score: 2.898\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 2.896 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 5.386 | Valid Score: 2.895\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 2.895 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 6.324 | Valid Score: 2.877\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 2.877 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 44/100 | Training Loss: 4.965 | Valid Score: 2.886\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 2.877 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 45/100 | Training Loss: 4.589 | Valid Score: 2.882\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 2.877 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 46/100 | Training Loss: 5.380 | Valid Score: 2.885\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 2.877 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 5.098 | Valid Score: 2.860\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 2.860 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 4.435 | Valid Score: 2.839\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 2.839 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 49/100 | Training Loss: 5.770 | Valid Score: 2.850\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 2.839 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 50/100 | Training Loss: 4.828 | Valid Score: 2.865\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 2.839 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 51/100 | Training Loss: 6.585 | Valid Score: 2.860\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 2.839 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 52/100 | Training Loss: 4.793 | Valid Score: 2.861\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 2.839 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 53/100 | Training Loss: 4.450 | Valid Score: 2.873\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 2.839 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 54/100 | Training Loss: 5.777 | Valid Score: 2.874\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 2.839 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 55/100 | Training Loss: 5.974 | Valid Score: 2.859\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 2.839 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 56/100 | Training Loss: 4.908 | Valid Score: 2.869\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 2.839 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 57/100 | Training Loss: 4.502 | Valid Score: 2.872\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 2.839 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 58/100 | Training Loss: 4.560 | Valid Score: 2.870\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 2.839 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 2.839 \n",
            "\n",
            "Test Score: 3.448 \n",
            "\n",
            "Execution time: 29.839 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model5"
      ],
      "metadata": {
        "id": "iR5obdYhqH2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using graph convolutional<br>\n",
        "4 layer<br>\n",
        "drop out = 0.2"
      ],
      "metadata": {
        "id": "Z7ooqS5TqH2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class model5(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv3 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv4 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "wF-3Vg3PtjAK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Compute Score of the Model"
      ],
      "metadata": {
        "id": "VXI2WSB_tjAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "      prediction = model(mol_dgl_graph, globals)\n",
        "      loss = loss_sum(prediction, labels)\n",
        "      final_loss += loss.item()\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "  return final_loss / num_tasks"
      ],
      "metadata": {
        "id": "1Vu9ObJHtjAM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss function"
      ],
      "metadata": {
        "id": "1C-Oq6RCtjAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "XK1kAdEktjAO"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training function"
      ],
      "metadata": {
        "id": "fZMjZ9iktjAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ],
      "metadata": {
        "id": "ukJD1CX_tjAP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model5(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = float('inf')\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ],
      "metadata": {
        "id": "PPGk2wTDtjAP"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compute test set score of the final saved model"
      ],
      "metadata": {
        "id": "_aMFpTYztjAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_evaluate():\n",
        "    final_model = model5(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(val_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ],
      "metadata": {
        "id": "29Mcn6BLtjAP"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model and evaluate its performance"
      ],
      "metadata": {
        "id": "aCZjpFdJtjAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "id": "nXFj9phvtjAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6646a8c2-90ec-43c0-cf81-8389c8fa3de4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 10.395 | Valid Score: 4.086\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 4.086 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 9.660 | Valid Score: 4.023\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 4.023 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 10.658 | Valid Score: 3.961\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 3.961 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 9.234 | Valid Score: 3.899\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 3.899 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 8.142 | Valid Score: 3.832\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 3.832 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 8.313 | Valid Score: 3.760\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 3.760 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 8.065 | Valid Score: 3.684\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 3.684 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 7.192 | Valid Score: 3.603\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 3.603 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 7.419 | Valid Score: 3.517\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 3.517 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 6.784 | Valid Score: 3.428\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 3.428 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 6.431 | Valid Score: 3.341\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 3.341 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 6.388 | Valid Score: 3.257\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 3.257 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 7.232 | Valid Score: 3.181\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 3.181 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 5.582 | Valid Score: 3.116\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 3.116 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 5.815 | Valid Score: 3.064\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 3.064 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 5.425 | Valid Score: 3.027\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 3.027 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 5.944 | Valid Score: 2.999\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 2.999 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 6.088 | Valid Score: 2.978\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 2.978 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 5.542 | Valid Score: 2.978\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 2.978 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 5.175 | Valid Score: 2.972\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 2.972 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 21/100 | Training Loss: 5.530 | Valid Score: 2.973\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 2.972 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 22/100 | Training Loss: 5.434 | Valid Score: 2.973\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 2.972 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 23/100 | Training Loss: 5.515 | Valid Score: 2.974\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 2.972 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 24/100 | Training Loss: 5.763 | Valid Score: 2.976\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 2.972 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 25/100 | Training Loss: 5.409 | Valid Score: 2.978\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 2.972 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 5.406 | Valid Score: 2.971\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 2.971 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 5.118 | Valid Score: 2.961\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 2.961 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 4.994 | Valid Score: 2.956\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 2.956 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 5.512 | Valid Score: 2.956\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 2.956 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 30/100 | Training Loss: 6.726 | Valid Score: 2.959\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 2.956 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 4.746 | Valid Score: 2.944\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 2.944 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 5.587 | Valid Score: 2.932\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 2.932 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 33/100 | Training Loss: 4.696 | Valid Score: 2.939\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 2.932 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 34/100 | Training Loss: 4.840 | Valid Score: 2.935\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 2.932 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 4.680 | Valid Score: 2.930\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 2.930 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 5.524 | Valid Score: 2.917\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 2.917 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 4.649 | Valid Score: 2.894\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 2.894 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 38/100 | Training Loss: 5.139 | Valid Score: 2.894\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 2.894 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 39/100 | Training Loss: 4.795 | Valid Score: 2.895\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 2.894 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 40/100 | Training Loss: 5.236 | Valid Score: 2.899\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 2.894 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 7.518 | Valid Score: 2.893\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 2.893 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 5.561 | Valid Score: 2.884\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 2.884 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 43/100 | Training Loss: 4.782 | Valid Score: 2.897\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 2.884 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 44/100 | Training Loss: 4.626 | Valid Score: 2.904\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 2.884 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 45/100 | Training Loss: 5.044 | Valid Score: 2.896\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 2.884 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 46/100 | Training Loss: 5.080 | Valid Score: 2.889\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 2.884 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 4.570 | Valid Score: 2.883\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 2.883 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 4.766 | Valid Score: 2.871\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 2.871 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 4.767 | Valid Score: 2.853\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 2.853 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 4.837 | Valid Score: 2.847\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 2.847 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 51/100 | Training Loss: 5.691 | Valid Score: 2.866\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 2.847 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 52/100 | Training Loss: 5.141 | Valid Score: 2.871\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 2.847 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 53/100 | Training Loss: 4.335 | Valid Score: 2.876\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 2.847 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 54/100 | Training Loss: 5.365 | Valid Score: 2.876\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 2.847 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 55/100 | Training Loss: 4.541 | Valid Score: 2.847\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 2.847 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 4.448 | Valid Score: 2.842\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 2.842 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 4.721 | Valid Score: 2.847\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 2.842 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 58/100 | Training Loss: 4.761 | Valid Score: 2.874\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 2.842 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 59/100 | Training Loss: 5.554 | Valid Score: 2.857\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 2.842 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 4.405 | Valid Score: 2.840\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 2.840 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 5.390 | Valid Score: 2.839\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 2.839 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 62/100 | Training Loss: 4.375 | Valid Score: 2.841\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 2.839 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 4.391 | Valid Score: 2.832\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 2.832 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 64/100 | Training Loss: 4.250 | Valid Score: 2.836\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 2.832 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 4.776 | Valid Score: 2.827\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 2.827 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 66/100 | Training Loss: 4.349 | Valid Score: 2.827\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 2.827 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 67/100 | Training Loss: 4.627 | Valid Score: 2.833\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 2.827 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 68/100 | Training Loss: 4.154 | Valid Score: 2.846\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 2.827 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 69/100 | Training Loss: 4.622 | Valid Score: 2.830\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 2.827 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 4.771 | Valid Score: 2.795\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 2.795 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 4.670 | Valid Score: 2.790\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 2.790 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 72/100 | Training Loss: 4.424 | Valid Score: 2.815\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 2.790 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 73/100 | Training Loss: 5.136 | Valid Score: 2.833\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 2.790 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 74/100 | Training Loss: 5.570 | Valid Score: 2.812\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 2.790 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 75/100 | Training Loss: 4.556 | Valid Score: 2.799\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 2.790 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 76/100 | Training Loss: 4.289 | Valid Score: 2.809\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 2.790 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 77/100 | Training Loss: 4.370 | Valid Score: 2.814\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 2.790 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 78/100 | Training Loss: 4.186 | Valid Score: 2.794\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 2.790 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 79/100 | Training Loss: 4.683 | Valid Score: 2.793\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 2.790 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 80/100 | Training Loss: 4.469 | Valid Score: 2.797\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 2.790 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 81/100 | Training Loss: 4.275 | Valid Score: 2.800\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 2.790 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 2.790 \n",
            "\n",
            "Test Score: 3.229 \n",
            "\n",
            "Execution time: 41.222 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model6"
      ],
      "metadata": {
        "id": "WNKD0HMuqNXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using graph sage<br>\n",
        "4 layer<br>\n",
        "no drop out"
      ],
      "metadata": {
        "id": "RNgbpe2KqNXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class model6(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.conv3 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.conv4 = SAGEConv(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "El3VKQTpts3L"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Compute Score of the Model"
      ],
      "metadata": {
        "id": "dnJeVyDkts3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "      prediction = model(mol_dgl_graph, globals)\n",
        "      loss = loss_sum(prediction, labels)\n",
        "      final_loss += loss.item()\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "  return final_loss / num_tasks"
      ],
      "metadata": {
        "id": "sKg0rU_Ots3N"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss function"
      ],
      "metadata": {
        "id": "vG5MMsATts3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "qqUwXJuUts3O"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training function"
      ],
      "metadata": {
        "id": "dQVdV11mts3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ],
      "metadata": {
        "id": "2uYwcZ9Bts3P"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model6(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = float('inf')\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ],
      "metadata": {
        "id": "kiF9v0kHts3P"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compute test set score of the final saved model"
      ],
      "metadata": {
        "id": "imGeTGYLts3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_evaluate():\n",
        "    final_model = model6(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(val_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ],
      "metadata": {
        "id": "ZGFnl1wHts3Q"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model and evaluate its performance"
      ],
      "metadata": {
        "id": "L5TlMhgvts3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "id": "xnKwWclLts3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ab3118-cd5c-4bf7-b4c9-dfd346b071f8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 10.606 | Valid Score: 4.185\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 4.185 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 10.544 | Valid Score: 4.162\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 4.162 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 11.403 | Valid Score: 4.133\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 4.133 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 10.285 | Valid Score: 4.093\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 4.093 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 10.992 | Valid Score: 4.034\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 4.034 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 9.109 | Valid Score: 3.948\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 3.948 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 9.141 | Valid Score: 3.826\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 3.826 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 8.125 | Valid Score: 3.657\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 3.657 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 6.688 | Valid Score: 3.442\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 3.442 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 6.349 | Valid Score: 3.205\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 3.205 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 5.966 | Valid Score: 3.001\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 3.001 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 5.901 | Valid Score: 2.923\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 2.923 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 13/100 | Training Loss: 5.180 | Valid Score: 2.949\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 2.923 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 14/100 | Training Loss: 5.741 | Valid Score: 2.967\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 2.923 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 15/100 | Training Loss: 6.267 | Valid Score: 2.961\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 2.923 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 16/100 | Training Loss: 6.494 | Valid Score: 2.940\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 2.923 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 17/100 | Training Loss: 5.782 | Valid Score: 2.926\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 2.923 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 5.450 | Valid Score: 2.900\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 2.900 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 5.102 | Valid Score: 2.885\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 2.885 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 20/100 | Training Loss: 6.862 | Valid Score: 2.889\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 2.885 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 5.027 | Valid Score: 2.876\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 2.876 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 4.673 | Valid Score: 2.847\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 2.847 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 4.737 | Valid Score: 2.825\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 2.825 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 24/100 | Training Loss: 4.721 | Valid Score: 2.833\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 2.825 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 25/100 | Training Loss: 4.991 | Valid Score: 2.828\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 2.825 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 4.495 | Valid Score: 2.787\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 2.787 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 27/100 | Training Loss: 4.641 | Valid Score: 2.798\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 2.787 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 28/100 | Training Loss: 4.357 | Valid Score: 2.802\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 2.787 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 4.551 | Valid Score: 2.773\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 2.773 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 4.260 | Valid Score: 2.738\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 2.738 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 4.202 | Valid Score: 2.733\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 2.733 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 4.175 | Valid Score: 2.700\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 2.700 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 4.231 | Valid Score: 2.673\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 2.673 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 4.715 | Valid Score: 2.680\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 2.673 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 4.379 | Valid Score: 2.623\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 2.623 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 4.033 | Valid Score: 2.610\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 2.610 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 3.767 | Valid Score: 2.587\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 2.587 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 38/100 | Training Loss: 3.655 | Valid Score: 2.596\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 2.587 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 39/100 | Training Loss: 3.764 | Valid Score: 2.589\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 2.587 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 3.693 | Valid Score: 2.567\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 2.567 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 3.830 | Valid Score: 2.556\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 2.556 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 4.286 | Valid Score: 2.538\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 2.538 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 3.752 | Valid Score: 2.504\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 2.504 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 3.495 | Valid Score: 2.483\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 2.483 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 3.901 | Valid Score: 2.468\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 2.468 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 46/100 | Training Loss: 3.765 | Valid Score: 2.547\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 2.468 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 47/100 | Training Loss: 3.774 | Valid Score: 2.533\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 2.468 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 3.366 | Valid Score: 2.417\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 2.417 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 3.269 | Valid Score: 2.407\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 2.407 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 50/100 | Training Loss: 4.007 | Valid Score: 2.453\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 2.407 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 51/100 | Training Loss: 3.387 | Valid Score: 2.427\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 2.407 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 3.535 | Valid Score: 2.386\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 2.386 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 3.888 | Valid Score: 2.354\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 2.354 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 54/100 | Training Loss: 3.339 | Valid Score: 2.370\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 2.354 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 3.670 | Valid Score: 2.309\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 2.309 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 3.295 | Valid Score: 2.296\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 2.296 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 3.421 | Valid Score: 2.307\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 2.296 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 58/100 | Training Loss: 3.261 | Valid Score: 2.305\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 2.296 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 59/100 | Training Loss: 3.165 | Valid Score: 2.328\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 2.296 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 3.069 | Valid Score: 2.258\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 2.258 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 2.997 | Valid Score: 2.223\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 2.223 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 62/100 | Training Loss: 3.019 | Valid Score: 2.270\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 2.223 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 63/100 | Training Loss: 2.847 | Valid Score: 2.273\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 2.223 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 64/100 | Training Loss: 2.937 | Valid Score: 2.232\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 2.223 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 65/100 | Training Loss: 3.073 | Valid Score: 2.225\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 2.223 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 66/100 | Training Loss: 3.182 | Valid Score: 2.237\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 2.223 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 3.082 | Valid Score: 2.186\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 2.186 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 2.905 | Valid Score: 2.149\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 2.149 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 69/100 | Training Loss: 2.972 | Valid Score: 2.225\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 2.149 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 70/100 | Training Loss: 3.498 | Valid Score: 2.211\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 2.149 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 2.818 | Valid Score: 2.082\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 2.082 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 72/100 | Training Loss: 2.941 | Valid Score: 2.147\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 2.082 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 73/100 | Training Loss: 2.707 | Valid Score: 2.202\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 2.082 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 74/100 | Training Loss: 2.887 | Valid Score: 2.131\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 2.082 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 75/100 | Training Loss: 2.887 | Valid Score: 2.119\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 2.082 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 76/100 | Training Loss: 2.750 | Valid Score: 2.124\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 2.082 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 77/100 | Training Loss: 2.937 | Valid Score: 2.114\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 2.082 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 78/100 | Training Loss: 3.134 | Valid Score: 2.088\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 2.082 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 2.641 | Valid Score: 2.037\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 2.037 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 80/100 | Training Loss: 2.701 | Valid Score: 2.042\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 2.037 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 81/100 | Training Loss: 2.668 | Valid Score: 2.050\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 2.037 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 82/100 | Training Loss: 3.412 | Valid Score: 2.094\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 2.037 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 83/100 | Training Loss: 2.777 | Valid Score: 2.023\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 2.023 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 84/100 | Training Loss: 2.477 | Valid Score: 1.973\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.973 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 85/100 | Training Loss: 2.557 | Valid Score: 2.018\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.973 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 86/100 | Training Loss: 2.656 | Valid Score: 1.969\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.969 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 2.552 | Valid Score: 1.962\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.962 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 88/100 | Training Loss: 3.420 | Valid Score: 1.951\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.951 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 2.898 | Valid Score: 1.920\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.920 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 90/100 | Training Loss: 2.749 | Valid Score: 1.927\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.920 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 91/100 | Training Loss: 2.655 | Valid Score: 2.009\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.920 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 92/100 | Training Loss: 2.361 | Valid Score: 1.927\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.920 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 93/100 | Training Loss: 2.691 | Valid Score: 1.880\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.880 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 94/100 | Training Loss: 2.526 | Valid Score: 1.904\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.880 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 95/100 | Training Loss: 2.318 | Valid Score: 1.930\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.880 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 96/100 | Training Loss: 2.399 | Valid Score: 1.945\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.880 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 97/100 | Training Loss: 2.475 | Valid Score: 1.912\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.880 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 98/100 | Training Loss: 2.386 | Valid Score: 1.859\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.859 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 99/100 | Training Loss: 3.642 | Valid Score: 1.866\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.859 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 100/100 | Training Loss: 2.475 | Valid Score: 1.832\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.832 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.832 \n",
            "\n",
            "Test Score: 2.286 \n",
            "\n",
            "Execution time: 51.365 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model7"
      ],
      "metadata": {
        "id": "ngSyl5c9qNXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using graph sage<br>\n",
        "4 layer<br>\n",
        "drop out = 0.1"
      ],
      "metadata": {
        "id": "tacXfCYhqNXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class model7(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.conv3 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.conv4 = SAGEConv(self.hidden_size, self.num_tasks)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "QGztdTrntxyf"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Compute Score of the Model"
      ],
      "metadata": {
        "id": "tag3ur1Ytxyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "      prediction = model(mol_dgl_graph, globals)\n",
        "      loss = loss_sum(prediction, labels)\n",
        "      final_loss += loss.item()\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "  return final_loss / num_tasks"
      ],
      "metadata": {
        "id": "vZQ8fYAQtxym"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss function"
      ],
      "metadata": {
        "id": "agK_ABIEtxym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "tX8J9gA-txym"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training function"
      ],
      "metadata": {
        "id": "1qb7Bfiftxym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ],
      "metadata": {
        "id": "SMk5L0KFtxym"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model7(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = float('inf')\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ],
      "metadata": {
        "id": "R-jJUhJptxym"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compute test set score of the final saved model"
      ],
      "metadata": {
        "id": "nLIKaviGtxyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_evaluate():\n",
        "    final_model = model7(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(val_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ],
      "metadata": {
        "id": "Jpy_7bxntxyn"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model and evaluate its performance"
      ],
      "metadata": {
        "id": "AM1Lxxj3txyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "id": "0-rn50yntxyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09dbcc01-1dd1-4cf3-fa88-886c65613a48"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 11.323 | Valid Score: 4.162\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 4.162 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 10.133 | Valid Score: 4.127\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 4.127 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 11.501 | Valid Score: 4.083\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 4.083 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 9.883 | Valid Score: 4.023\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 4.023 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 9.681 | Valid Score: 3.941\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 3.941 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 8.843 | Valid Score: 3.829\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 3.829 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 8.030 | Valid Score: 3.680\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 3.680 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 7.529 | Valid Score: 3.491\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 3.491 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 6.676 | Valid Score: 3.278\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 3.278 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 5.597 | Valid Score: 3.095\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 3.095 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 5.476 | Valid Score: 2.974\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 2.974 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 5.848 | Valid Score: 2.939\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 2.939 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 6.925 | Valid Score: 2.936\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 2.936 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 5.246 | Valid Score: 2.914\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 2.914 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 15/100 | Training Loss: 5.249 | Valid Score: 2.925\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 2.914 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 16/100 | Training Loss: 5.384 | Valid Score: 2.938\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 2.914 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 6.182 | Valid Score: 2.897\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 2.897 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 5.470 | Valid Score: 2.866\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 2.866 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 19/100 | Training Loss: 4.994 | Valid Score: 2.870\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 2.866 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 5.379 | Valid Score: 2.863\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 2.863 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 21/100 | Training Loss: 4.873 | Valid Score: 2.868\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 2.863 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 22/100 | Training Loss: 5.148 | Valid Score: 2.866\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 2.863 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 23/100 | Training Loss: 4.971 | Valid Score: 2.916\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 2.863 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 24/100 | Training Loss: 4.925 | Valid Score: 2.899\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 2.863 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 25/100 | Training Loss: 5.667 | Valid Score: 2.880\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 2.863 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 4.928 | Valid Score: 2.832\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 2.832 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 4.523 | Valid Score: 2.802\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 2.802 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 4.333 | Valid Score: 2.765\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 2.765 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 4.517 | Valid Score: 2.751\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 2.751 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 30/100 | Training Loss: 4.942 | Valid Score: 2.767\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 2.751 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 31/100 | Training Loss: 4.254 | Valid Score: 2.766\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 2.751 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 32/100 | Training Loss: 4.108 | Valid Score: 2.771\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 2.751 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 33/100 | Training Loss: 4.803 | Valid Score: 2.757\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 2.751 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 4.850 | Valid Score: 2.734\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 2.734 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 4.306 | Valid Score: 2.693\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 2.693 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 4.383 | Valid Score: 2.673\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 2.673 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 4.062 | Valid Score: 2.659\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 2.659 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 4.224 | Valid Score: 2.649\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 2.649 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 39/100 | Training Loss: 4.725 | Valid Score: 2.702\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 2.649 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 40/100 | Training Loss: 4.009 | Valid Score: 2.675\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 2.649 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 3.769 | Valid Score: 2.623\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 2.623 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 4.032 | Valid Score: 2.605\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 2.605 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 43/100 | Training Loss: 3.674 | Valid Score: 2.625\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 2.605 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 44/100 | Training Loss: 3.829 | Valid Score: 2.625\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 2.605 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 3.775 | Valid Score: 2.587\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 2.587 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 3.962 | Valid Score: 2.563\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 2.563 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 4.154 | Valid Score: 2.525\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 2.525 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 48/100 | Training Loss: 3.637 | Valid Score: 2.528\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 2.525 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 49/100 | Training Loss: 3.461 | Valid Score: 2.529\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 2.525 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 50/100 | Training Loss: 3.510 | Valid Score: 2.532\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 2.525 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 4.018 | Valid Score: 2.495\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 2.495 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 3.557 | Valid Score: 2.481\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 2.481 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 4.399 | Valid Score: 2.464\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 2.464 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 3.414 | Valid Score: 2.402\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 2.402 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 55/100 | Training Loss: 3.355 | Valid Score: 2.440\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 2.402 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 56/100 | Training Loss: 3.511 | Valid Score: 2.508\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 2.402 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 57/100 | Training Loss: 3.193 | Valid Score: 2.434\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 2.402 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 3.322 | Valid Score: 2.398\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 2.398 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 59/100 | Training Loss: 3.443 | Valid Score: 2.416\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 2.398 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 60/100 | Training Loss: 3.649 | Valid Score: 2.412\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 2.398 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 3.443 | Valid Score: 2.397\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 2.397 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 3.339 | Valid Score: 2.350\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 2.350 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 63/100 | Training Loss: 4.299 | Valid Score: 2.372\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 2.350 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 3.364 | Valid Score: 2.344\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 2.344 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 65/100 | Training Loss: 3.367 | Valid Score: 2.346\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 2.344 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 66/100 | Training Loss: 3.179 | Valid Score: 2.379\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 2.344 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 3.233 | Valid Score: 2.321\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 2.321 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 2.990 | Valid Score: 2.247\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 2.247 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 69/100 | Training Loss: 3.134 | Valid Score: 2.291\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 2.247 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 70/100 | Training Loss: 2.952 | Valid Score: 2.308\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 2.247 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 3.289 | Valid Score: 2.239\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 2.239 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 3.513 | Valid Score: 2.222\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 2.222 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 73/100 | Training Loss: 2.994 | Valid Score: 2.233\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 2.222 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 74/100 | Training Loss: 2.936 | Valid Score: 2.238\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 2.222 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 3.428 | Valid Score: 2.193\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 2.193 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 76/100 | Training Loss: 3.152 | Valid Score: 2.233\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 2.193 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 77/100 | Training Loss: 3.814 | Valid Score: 2.243\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 2.193 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 2.978 | Valid Score: 2.154\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 2.154 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 79/100 | Training Loss: 3.661 | Valid Score: 2.170\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 2.154 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 80/100 | Training Loss: 2.687 | Valid Score: 2.205\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 2.154 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 3.202 | Valid Score: 2.120\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 2.120 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 82/100 | Training Loss: 2.795 | Valid Score: 2.074\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 2.074 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 83/100 | Training Loss: 2.679 | Valid Score: 2.126\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 2.074 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 84/100 | Training Loss: 2.938 | Valid Score: 2.101\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 2.074 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 85/100 | Training Loss: 2.689 | Valid Score: 2.060\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 2.060 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 86/100 | Training Loss: 2.724 | Valid Score: 2.087\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 2.060 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 87/100 | Training Loss: 2.662 | Valid Score: 2.064\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 2.060 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 88/100 | Training Loss: 2.860 | Valid Score: 2.083\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 2.060 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 3.052 | Valid Score: 2.058\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 2.058 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 90/100 | Training Loss: 2.846 | Valid Score: 2.023\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 2.023 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 91/100 | Training Loss: 3.490 | Valid Score: 2.056\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 2.023 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 92/100 | Training Loss: 2.700 | Valid Score: 2.009\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 2.009 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 93/100 | Training Loss: 2.557 | Valid Score: 2.024\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 2.009 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 94/100 | Training Loss: 2.961 | Valid Score: 2.004\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 2.004 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 95/100 | Training Loss: 2.551 | Valid Score: 1.985\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.985 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 96/100 | Training Loss: 2.747 | Valid Score: 1.999\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.985 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 97/100 | Training Loss: 2.909 | Valid Score: 1.933\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.933 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 98/100 | Training Loss: 2.472 | Valid Score: 1.930\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.930 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 99/100 | Training Loss: 2.457 | Valid Score: 2.041\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.930 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 100/100 | Training Loss: 2.768 | Valid Score: 1.969\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.930 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.930 \n",
            "\n",
            "Test Score: 2.368 \n",
            "\n",
            "Execution time: 53.246 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model8"
      ],
      "metadata": {
        "id": "XF6eGyJwqNXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using graph sage<br>\n",
        "4 layer<br>\n",
        "drop out = 0.2"
      ],
      "metadata": {
        "id": "UZINqS7aqNXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class model8(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.conv3 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.conv4 = SAGEConv(self.hidden_size, self.num_tasks)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "51QPtwZht2r_"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Compute Score of the Model"
      ],
      "metadata": {
        "id": "zn7ausjVt2sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "      prediction = model(mol_dgl_graph, globals)\n",
        "      loss = loss_sum(prediction, labels)\n",
        "      final_loss += loss.item()\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "  return final_loss / num_tasks"
      ],
      "metadata": {
        "id": "YpyVgGfRt2sE"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss function"
      ],
      "metadata": {
        "id": "zFYj7qpIt2sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "7c4TdOeOt2sE"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training function"
      ],
      "metadata": {
        "id": "RiUaEYmkt2sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ],
      "metadata": {
        "id": "3EYMv1FWt2sE"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = model8(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = float('inf')\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ],
      "metadata": {
        "id": "EA0O_-drt2sF"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compute test set score of the final saved model"
      ],
      "metadata": {
        "id": "-dsquqtNt2sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_evaluate():\n",
        "    final_model = model8(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(val_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ],
      "metadata": {
        "id": "S8GkmjDdt2sF"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model and evaluate its performance"
      ],
      "metadata": {
        "id": "-STxAS39t2sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "id": "jmMBMmKit2sF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf7c518f-3c45-453b-c2d6-6619c3015340"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 10.205 | Valid Score: 4.199\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 4.199 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 10.323 | Valid Score: 4.174\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 4.174 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 10.152 | Valid Score: 4.146\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 4.146 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 10.503 | Valid Score: 4.112\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 4.112 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 10.584 | Valid Score: 4.066\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 4.066 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 11.355 | Valid Score: 3.999\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 3.999 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 8.939 | Valid Score: 3.900\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 3.900 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 9.117 | Valid Score: 3.759\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 3.759 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 7.655 | Valid Score: 3.569\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 3.569 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 6.910 | Valid Score: 3.342\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 3.342 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 5.956 | Valid Score: 3.112\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 3.112 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 6.352 | Valid Score: 2.954\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 2.954 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 6.119 | Valid Score: 2.922\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 2.922 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 14/100 | Training Loss: 5.737 | Valid Score: 2.962\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 2.922 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 15/100 | Training Loss: 5.687 | Valid Score: 2.989\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 2.922 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 16/100 | Training Loss: 5.381 | Valid Score: 2.968\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 2.922 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 17/100 | Training Loss: 4.998 | Valid Score: 2.964\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 2.922 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 18/100 | Training Loss: 5.397 | Valid Score: 2.952\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 2.922 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 5.140 | Valid Score: 2.917\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 2.917 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 5.290 | Valid Score: 2.915\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 2.915 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 4.969 | Valid Score: 2.913\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 2.913 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 4.989 | Valid Score: 2.895\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 2.895 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 5.482 | Valid Score: 2.891\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 2.891 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 4.837 | Valid Score: 2.864\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 2.864 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 25/100 | Training Loss: 6.041 | Valid Score: 2.865\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 2.864 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 5.195 | Valid Score: 2.852\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 2.852 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 27/100 | Training Loss: 5.027 | Valid Score: 2.864\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 2.852 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 28/100 | Training Loss: 4.755 | Valid Score: 2.888\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 2.852 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 29/100 | Training Loss: 4.701 | Valid Score: 2.859\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 2.852 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 4.567 | Valid Score: 2.816\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 2.816 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 5.248 | Valid Score: 2.812\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 2.812 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 32/100 | Training Loss: 4.527 | Valid Score: 2.839\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 2.812 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 33/100 | Training Loss: 4.699 | Valid Score: 2.833\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 2.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 4.639 | Valid Score: 2.782\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 2.782 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 4.911 | Valid Score: 2.751\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 2.751 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 5.618 | Valid Score: 2.724\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 2.724 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 37/100 | Training Loss: 4.555 | Valid Score: 2.738\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 2.724 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 38/100 | Training Loss: 5.303 | Valid Score: 2.753\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 2.724 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 39/100 | Training Loss: 4.734 | Valid Score: 2.767\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 2.724 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 40/100 | Training Loss: 4.385 | Valid Score: 2.793\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 2.724 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 41/100 | Training Loss: 4.174 | Valid Score: 2.750\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 2.724 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 4.308 | Valid Score: 2.701\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 2.701 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 4.032 | Valid Score: 2.686\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 2.686 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 44/100 | Training Loss: 4.328 | Valid Score: 2.695\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 2.686 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 45/100 | Training Loss: 4.806 | Valid Score: 2.710\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 2.686 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 4.082 | Valid Score: 2.659\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 2.659 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 4.499 | Valid Score: 2.649\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 2.649 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 3.684 | Valid Score: 2.625\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 2.625 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 49/100 | Training Loss: 3.770 | Valid Score: 2.626\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 2.625 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 4.667 | Valid Score: 2.621\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 2.621 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 3.784 | Valid Score: 2.577\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 2.577 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 52/100 | Training Loss: 3.770 | Valid Score: 2.603\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 2.577 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 53/100 | Training Loss: 3.910 | Valid Score: 2.620\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 2.577 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 54/100 | Training Loss: 3.731 | Valid Score: 2.597\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 2.577 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 55/100 | Training Loss: 4.172 | Valid Score: 2.605\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 2.577 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 56/100 | Training Loss: 3.985 | Valid Score: 2.599\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 2.577 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 57/100 | Training Loss: 3.987 | Valid Score: 2.548\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 2.548 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 3.839 | Valid Score: 2.537\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 2.537 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 59/100 | Training Loss: 3.835 | Valid Score: 2.537\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 2.537 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 4.032 | Valid Score: 2.511\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 2.511 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 3.931 | Valid Score: 2.445\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 2.445 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 62/100 | Training Loss: 3.723 | Valid Score: 2.520\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 2.445 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 63/100 | Training Loss: 3.504 | Valid Score: 2.534\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 2.445 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 64/100 | Training Loss: 3.890 | Valid Score: 2.455\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 2.445 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 3.827 | Valid Score: 2.424\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 2.424 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 66/100 | Training Loss: 3.163 | Valid Score: 2.432\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 2.424 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 67/100 | Training Loss: 3.212 | Valid Score: 2.449\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 2.424 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 3.779 | Valid Score: 2.411\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 2.411 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 3.714 | Valid Score: 2.340\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 2.340 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 3.469 | Valid Score: 2.337\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 2.337 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 71/100 | Training Loss: 3.610 | Valid Score: 2.353\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 2.337 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 72/100 | Training Loss: 3.203 | Valid Score: 2.354\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 2.337 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 3.669 | Valid Score: 2.307\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 2.307 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 74/100 | Training Loss: 3.010 | Valid Score: 2.311\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 2.307 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 2.930 | Valid Score: 2.299\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 2.299 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 76/100 | Training Loss: 3.523 | Valid Score: 2.287\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 2.287 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 77/100 | Training Loss: 2.953 | Valid Score: 2.293\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 2.287 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 2.962 | Valid Score: 2.258\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 2.258 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 2.880 | Valid Score: 2.233\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 2.233 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 80/100 | Training Loss: 3.154 | Valid Score: 2.254\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 2.233 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 2.813 | Valid Score: 2.182\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 2.182 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 82/100 | Training Loss: 3.115 | Valid Score: 2.205\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 2.182 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 83/100 | Training Loss: 2.926 | Valid Score: 2.228\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 2.182 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 84/100 | Training Loss: 3.657 | Valid Score: 2.171\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 2.171 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 85/100 | Training Loss: 2.904 | Valid Score: 2.105\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 2.105 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 86/100 | Training Loss: 2.923 | Valid Score: 2.138\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 2.105 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 87/100 | Training Loss: 2.905 | Valid Score: 2.143\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 2.105 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 88/100 | Training Loss: 2.725 | Valid Score: 2.141\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 2.105 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 89/100 | Training Loss: 2.680 | Valid Score: 2.120\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 2.105 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 90/100 | Training Loss: 2.742 | Valid Score: 2.105\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 2.105 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 91/100 | Training Loss: 2.856 | Valid Score: 2.134\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 2.105 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 92/100 | Training Loss: 3.045 | Valid Score: 2.093\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 2.093 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 93/100 | Training Loss: 2.993 | Valid Score: 2.090\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 2.090 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 94/100 | Training Loss: 2.703 | Valid Score: 2.030\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 2.030 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 95/100 | Training Loss: 2.711 | Valid Score: 2.009\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 2.009 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 96/100 | Training Loss: 2.708 | Valid Score: 2.031\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 2.009 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 97/100 | Training Loss: 2.490 | Valid Score: 2.025\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 2.009 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 98/100 | Training Loss: 2.708 | Valid Score: 2.009\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 2.009 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 99/100 | Training Loss: 2.462 | Valid Score: 2.059\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 2.009 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 100/100 | Training Loss: 2.670 | Valid Score: 1.998\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.998 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.998 \n",
            "\n",
            "Test Score: 2.462 \n",
            "\n",
            "Execution time: 49.740 seconds\n"
          ]
        }
      ]
    }
  ]
}